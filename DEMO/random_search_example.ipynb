{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "from ast import arg\n",
    "from DeepMTP.main import DeepMTP\n",
    "from DeepMTP.hpo_worker import BaseWorker\n",
    "from DeepMTP.random_search import RandomSearch\n",
    "from DeepMTP.dataset import load_process_MLC, load_process_MTR, load_process_DP, process_dummy_MLC, process_dummy_MTR, process_dummy_DP, load_process_MC\n",
    "from DeepMTP.utils.data_utils import data_process, BaseDataset\n",
    "from DeepMTP.utils.utils import generate_config\n",
    "import ConfigSpace as CS\n",
    "import ConfigSpace.hyperparameters as CSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(batch_norm | instance_branch_layers > 1 || batch_norm | target_branch_layers > 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the configuration space\n",
    "cs= CS.ConfigurationSpace()\n",
    "\n",
    "lr= CSH.UniformFloatHyperparameter(\n",
    "    \"learning_rate\", lower=1e-6, upper=1e-3, default_value=\"1e-3\", log=True\n",
    ")\n",
    "cs.add_hyperparameters([lr])\n",
    "\n",
    "embedding_size= CSH.UniformIntegerHyperparameter(\n",
    "    \"embedding_size\", lower=8, upper=2048, default_value=64, log=False\n",
    ")\n",
    "\n",
    "instance_branch_layers= CSH.UniformIntegerHyperparameter(\n",
    "    \"instance_branch_layers\", lower=1, upper=2, default_value=1, log=False\n",
    ")\n",
    "\n",
    "instance_branch_nodes_per_layer= CSH.UniformIntegerHyperparameter(\n",
    "    \"instance_branch_nodes_per_layer\", lower=8, upper=2048, default_value=64, log=False\n",
    ")\n",
    "\n",
    "target_branch_layers = CSH.UniformIntegerHyperparameter(\n",
    "    \"target_branch_layers\", lower=1, upper=2, default_value=1, log=False\n",
    ")\n",
    "\n",
    "target_branch_nodes_per_layer = CSH.UniformIntegerHyperparameter(\n",
    "    \"target_branch_nodes_per_layer\", lower=8, upper=2048, default_value=64, log=False\n",
    ")\n",
    "\n",
    "dropout_rate = CSH.UniformFloatHyperparameter(\n",
    "    \"dropout_rate\", lower=0.0, upper=0.9, default_value=0.4, log=False\n",
    ")\n",
    "\n",
    "batch_norm = CSH.CategoricalHyperparameter(\"batch_norm\", [True, False])\n",
    "\n",
    "cs.add_hyperparameters(\n",
    "    [\n",
    "        embedding_size,\n",
    "        instance_branch_layers,\n",
    "        instance_branch_nodes_per_layer,\n",
    "        target_branch_layers,\n",
    "        target_branch_nodes_per_layer,\n",
    "        dropout_rate,\n",
    "        batch_norm,\n",
    "    ]\n",
    ")\n",
    "\n",
    "cond = CS.GreaterThanCondition(dropout_rate, instance_branch_layers, 1)\n",
    "cond2 = CS.GreaterThanCondition(batch_norm, instance_branch_layers, 1)\n",
    "cond3 = CS.GreaterThanCondition(dropout_rate, target_branch_layers, 1)\n",
    "cond4 = CS.GreaterThanCondition(batch_norm, target_branch_layers, 1)\n",
    "\n",
    "cs.add_condition(CS.OrConjunction(cond, cond3))\n",
    "cs.add_condition(CS.OrConjunction(cond2, cond4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "yeast:undivided - exists, not redownloading\n",
      "Done\n",
      "Interaction file: 2d numpy array format detected\n",
      "Interaction file: checking format consistency... Passed\n",
      "Interaction file: checking instance id format consistency... Passed\n",
      "Interaction file: checking target id type consistency... Passed\n",
      "\n",
      "Interaction file: checking target variable type consistency... Passed\n",
      "Automatically detected type of target variable type: binary\n",
      "\n",
      "-- Test set was not provided, could not detect if novel instances exist or not \n",
      "-- Test set was not provided, could not detect if novel targets exist or not \n",
      "\n",
      "Instance features file: processing features... Done\n",
      "\n",
      "Cross input consistency for (numpy) interaction data and instance features checks out\n",
      "-- Same instance ids in the interaction and features files for the train set\n",
      "\n",
      "Splitting train to train-test according to validation setting B... Done\n",
      "Splitting train to train-val according to validation setting B... Done\n"
     ]
    }
   ],
   "source": [
    "data = load_process_MLC(dataset_name='yeast', variant='undivided')\n",
    "train, val, test, data_info = data_process(data, validation_setting='B', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detected_validation_setting': 'B',\n",
       " 'detected_problem_mode': 'classification',\n",
       " 'instance_branch_input_dim': 103,\n",
       " 'target_branch_input_dim': 14}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {    \n",
    "\n",
    "    'hpo_results_path': './random_search/',\n",
    "\n",
    "    'instance_branch_input_dim': data_info['instance_branch_input_dim'],\n",
    "    'target_branch_input_dim': data_info['target_branch_input_dim'],\n",
    "    'validation_setting': data_info['detected_validation_setting'],\n",
    "    'general_architecture_version': 'dot_product',\n",
    "    'problem_mode': data_info['detected_problem_mode'],\n",
    "\n",
    "    'compute_mode': 'cuda:1',\n",
    "    'train_batchsize': 512,\n",
    "    'val_batchsize': 512,\n",
    "    'num_epochs': 10,\n",
    "    'num_workers': 8,\n",
    "\n",
    "    'metrics': ['hamming_loss', 'auroc'],\n",
    "    'metrics_average': ['macro'],\n",
    "    'patience': 10,\n",
    "\n",
    "    'evaluate_train': True,\n",
    "    'evaluate_val': True,\n",
    "\n",
    "    'verbose': True,\n",
    "    'results_verbose': False,\n",
    "    'use_early_stopping': True,\n",
    "    'use_tensorboard_logger': True,\n",
    "    'wandb_project_name': None,\n",
    "    'wandb_project_entity': None,\n",
    "    'metric_to_optimize_early_stopping': 'loss',\n",
    "    'metric_to_optimize_best_epoch_selection': 'loss',\n",
    "\n",
    "    'instance_branch_architecture': 'MLP',\n",
    "\n",
    "    'target_branch_architecture': 'MLP',\n",
    "\n",
    "    'save_model': True,\n",
    "\n",
    "    'eval_every_n_epochs': 10,\n",
    "\n",
    "    'running_hpo': True,\n",
    "\n",
    "    'additional_info': {'budget': 9}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker = BaseWorker(\n",
    "    train, val, test, data_info, config, 'loss'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hpo_results_path': './random_search/',\n",
       " 'instance_branch_input_dim': 103,\n",
       " 'target_branch_input_dim': 14,\n",
       " 'validation_setting': 'B',\n",
       " 'enable_dot_product_version': True,\n",
       " 'problem_mode': 'classification',\n",
       " 'compute_mode': 'cuda:1',\n",
       " 'train_batchsize': 512,\n",
       " 'val_batchsize': 512,\n",
       " 'num_epochs': 10,\n",
       " 'num_workers': 8,\n",
       " 'metrics': ['hamming_loss', 'auroc'],\n",
       " 'metrics_average': ['macro'],\n",
       " 'patience': 10,\n",
       " 'evaluate_train': True,\n",
       " 'evaluate_val': True,\n",
       " 'verbose': True,\n",
       " 'results_verbose': False,\n",
       " 'use_early_stopping': True,\n",
       " 'use_tensorboard_logger': True,\n",
       " 'wandb_project_name': 'DeepMTP_v2',\n",
       " 'wandb_project_entity': 'diliadis',\n",
       " 'metric_to_optimize_early_stopping': 'loss',\n",
       " 'metric_to_optimize_best_epoch_selection': 'loss',\n",
       " 'instance_branch_architecture': 'MLP',\n",
       " 'target_branch_architecture': 'MLP',\n",
       " 'save_model': True,\n",
       " 'eval_every_n_epochs': 10,\n",
       " 'running_hpo': True,\n",
       " 'additional_info': {'budget': 9}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker.base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb = RandomSearch(\n",
    "    base_worker=worker,\n",
    "    configspace=cs,\n",
    "    budget=config['additional_info']['budget'],\n",
    "    max_num_epochs=config['num_epochs'], \n",
    "    direction=\"min\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Evaluating configuration... \n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-20 15:27:31.164 ERROR   wandb.jupyter: Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdiliadis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/wandb/run-20220620_152731-22awkrcb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/22awkrcb\" target=\"_blank\">major-dawn-378</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Done\n",
      "Epoch:2... Done\n",
      "  Validating... Done\n",
      "Epoch:3... Done\n",
      "  Validating... Done\n",
      "Epoch:4... Done\n",
      "  Validating... Done\n",
      "Epoch:5... Done\n",
      "  Validating... Done\n",
      "Epoch:6... Done\n",
      "  Validating... Done\n",
      "Epoch:7... Done\n",
      "  Validating... Done\n",
      "Epoch:8... Done\n",
      "  Validating... Done\n",
      "Epoch:9... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70868a83cf04847b85d6a577ef3ac98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▄▄▄▄▄▄▂▂▁</td></tr><tr><td>val_auroc_macro</td><td>▁█</td></tr><tr><td>val_hamming_loss_macro</td><td>█▁</td></tr><tr><td>val_loss</td><td>█████▇▅▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.54507</td></tr><tr><td>test_hamming_loss_macro</td><td>0.27214</td></tr><tr><td>train_auroc_macro</td><td>0.52284</td></tr><tr><td>train_hamming_loss_macro</td><td>0.30284</td></tr><tr><td>train_loss</td><td>0.53101</td></tr><tr><td>val_auroc_macro</td><td>0.5452</td></tr><tr><td>val_hamming_loss_macro</td><td>0.26031</td></tr><tr><td>val_loss</td><td>0.52101</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">major-dawn-378</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/22awkrcb\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/22awkrcb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220620_152731-22awkrcb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+-------------+\n",
      "|  mode | #epoch |  loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "| train |   0    | 0.8865 |       0.4225       |    0.5023   |\n",
      "| train |   1    | 0.6928 |         -          |      -      |\n",
      "| train |   2    | 0.6925 |         -          |      -      |\n",
      "| train |   3    | 0.692  |         -          |      -      |\n",
      "| train |   4    | 0.6907 |         -          |      -      |\n",
      "| train |   5    | 0.6856 |         -          |      -      |\n",
      "| train |   6    | 0.6612 |         -          |      -      |\n",
      "| train |   7    | 0.605  |         -          |      -      |\n",
      "| train |   8    | 0.5682 |         -          |      -      |\n",
      "| train |   9    | 0.531  |       0.3028       |    0.5228   |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 0.6929 |       0.2975       |    0.4893   |      0/10      |\n",
      "| val  |   1    | 0.6927 |         -          |      -      |      0/10      |\n",
      "| val  |   2    | 0.6923 |         -          |      -      |      0/10      |\n",
      "| val  |   3    | 0.6915 |         -          |      -      |      0/10      |\n",
      "| val  |   4    | 0.6892 |         -          |      -      |      0/10      |\n",
      "| val  |   5    | 0.6789 |         -          |      -      |      0/10      |\n",
      "| val  |   6    | 0.631  |         -          |      -      |      0/10      |\n",
      "| val  |   7    | 0.5816 |         -          |      -      |      0/10      |\n",
      "| val  |   8    | 0.5449 |         -          |      -      |      0/10      |\n",
      "| val  |   9    | 0.521  |       0.2603       |    0.5452   |      0/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   9    |  -   |       0.2721       |    0.5451   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "---- Finished evaluating configuration with score: 0.5210093806187311\n",
      "---- Evaluating configuration... \n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/wandb/run-20220620_152829-jxslyyti</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/jxslyyti\" target=\"_blank\">efficient-elevator-379</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Done\n",
      "Epoch:2... Done\n",
      "  Validating... Done\n",
      "Epoch:3... Done\n",
      "  Validating... Done\n",
      "Epoch:4... Done\n",
      "  Validating... Done\n",
      "Epoch:5... Done\n",
      "  Validating... Done\n",
      "Epoch:6... Done\n",
      "  Validating... Done\n",
      "Epoch:7... Done\n",
      "  Validating... Done\n",
      "Epoch:8... Done\n",
      "  Validating... Done\n",
      "Epoch:9... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173e0a34f84a460ab3a46dc0f1ba6c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>▁▁</td></tr><tr><td>train_loss</td><td>█▅▄▄▃▂▂▂▁▁</td></tr><tr><td>val_auroc_macro</td><td>▁█</td></tr><tr><td>val_hamming_loss_macro</td><td>█▁</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.49568</td></tr><tr><td>test_hamming_loss_macro</td><td>0.69613</td></tr><tr><td>train_auroc_macro</td><td>0.50447</td></tr><tr><td>train_hamming_loss_macro</td><td>0.30284</td></tr><tr><td>train_loss</td><td>0.69455</td></tr><tr><td>val_auroc_macro</td><td>0.51004</td></tr><tr><td>val_hamming_loss_macro</td><td>0.70214</td></tr><tr><td>val_loss</td><td>0.69446</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">efficient-elevator-379</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/jxslyyti\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/jxslyyti</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220620_152829-jxslyyti/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+-------------+\n",
      "|  mode | #epoch |  loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "| train |   0    | 0.7022 |       0.3028       |    0.5036   |\n",
      "| train |   1    | 0.699  |         -          |      -      |\n",
      "| train |   2    | 0.6982 |         -          |      -      |\n",
      "| train |   3    | 0.6974 |         -          |      -      |\n",
      "| train |   4    | 0.6967 |         -          |      -      |\n",
      "| train |   5    | 0.6962 |         -          |      -      |\n",
      "| train |   6    | 0.6957 |         -          |      -      |\n",
      "| train |   7    | 0.6953 |         -          |      -      |\n",
      "| train |   8    | 0.6949 |         -          |      -      |\n",
      "| train |   9    | 0.6946 |       0.3028       |    0.5045   |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 0.6996 |       0.7025       |    0.5013   |      0/10      |\n",
      "| val  |   1    | 0.6987 |         -          |      -      |      0/10      |\n",
      "| val  |   2    | 0.6979 |         -          |      -      |      0/10      |\n",
      "| val  |   3    | 0.6971 |         -          |      -      |      0/10      |\n",
      "| val  |   4    | 0.6965 |         -          |      -      |      0/10      |\n",
      "| val  |   5    | 0.696  |         -          |      -      |      0/10      |\n",
      "| val  |   6    | 0.6956 |         -          |      -      |      0/10      |\n",
      "| val  |   7    | 0.6951 |         -          |      -      |      0/10      |\n",
      "| val  |   8    | 0.6948 |         -          |      -      |      0/10      |\n",
      "| val  |   9    | 0.6945 |       0.7021       |     0.51    |      0/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   9    |  -   |       0.6961       |    0.4957   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "---- Finished evaluating configuration with score: 0.6944555838902792\n",
      "---- Evaluating configuration... \n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/wandb/run-20220620_152922-yji35s72</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/yji35s72\" target=\"_blank\">gallant-vortex-380</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Done\n",
      "Epoch:2... Done\n",
      "  Validating... Done\n",
      "Epoch:3... Done\n",
      "  Validating... Done\n",
      "Epoch:4... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 3\n",
      "Epoch:5... Done\n",
      "  Validating... Done\n",
      "Epoch:6... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 5\n",
      "Epoch:7... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 5\n",
      "Epoch:8... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 3 out of 10---------------------- best epoch currently 5\n",
      "Epoch:9... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "-----------------------------EarlyStopping counter: 4 out of 10---------------------- best epoch currently 5\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc220c3abab45639fa104f40c6911b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▆▅▅▄▃▃▂▂▁</td></tr><tr><td>val_auroc_macro</td><td>▁█</td></tr><tr><td>val_hamming_loss_macro</td><td>█▁</td></tr><tr><td>val_loss</td><td>▇▆▃▂▂▁▂▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.69084</td></tr><tr><td>test_hamming_loss_macro</td><td>0.19613</td></tr><tr><td>train_auroc_macro</td><td>0.85325</td></tr><tr><td>train_hamming_loss_macro</td><td>0.13259</td></tr><tr><td>train_loss</td><td>0.31125</td></tr><tr><td>val_auroc_macro</td><td>0.68162</td></tr><tr><td>val_hamming_loss_macro</td><td>0.22607</td></tr><tr><td>val_loss</td><td>0.50462</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">gallant-vortex-380</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/yji35s72\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/yji35s72</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220620_152922-yji35s72/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+-------------+\n",
      "|  mode | #epoch |  loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "| train |   0    | 0.5683 |       0.2593       |    0.4967   |\n",
      "| train |   1    | 0.4899 |         -          |      -      |\n",
      "| train |   2    | 0.4721 |         -          |      -      |\n",
      "| train |   3    | 0.4528 |         -          |      -      |\n",
      "| train |   4    | 0.4248 |         -          |      -      |\n",
      "| train |   5    | 0.4014 |         -          |      -      |\n",
      "| train |   6    | 0.3803 |         -          |      -      |\n",
      "| train |   7    | 0.3599 |         -          |      -      |\n",
      "| train |   8    | 0.3355 |         -          |      -      |\n",
      "| train |   9    | 0.3112 |       0.1326       |    0.8532   |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 0.4972 |       0.2297       |    0.5822   |      0/10      |\n",
      "| val  |   1    | 0.4897 |         -          |      -      |      0/10      |\n",
      "| val  |   2    | 0.4737 |         -          |      -      |      0/10      |\n",
      "| val  |   3    | 0.4643 |         -          |      -      |      0/10      |\n",
      "| val  |   4    | 0.466  |         -          |      -      |      1/10      |\n",
      "| val  |   5    | 0.4587 |         -          |      -      |      0/10      |\n",
      "| val  |   6    | 0.4658 |         -          |      -      |      1/10      |\n",
      "| val  |   7    | 0.4825 |         -          |      -      |      2/10      |\n",
      "| val  |   8    | 0.4924 |         -          |      -      |      3/10      |\n",
      "| val  |   9    | 0.5046 |       0.2261       |    0.6816   |      4/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   5    |  -   |       0.1961       |    0.6908   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "---- Finished evaluating configuration with score: 0.45870905617872876\n",
      "---- Evaluating configuration... \n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/wandb/run-20220620_153016-39yxjjah</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/39yxjjah\" target=\"_blank\">lunar-galaxy-381</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Done\n",
      "Epoch:2... Done\n",
      "  Validating... Done\n",
      "Epoch:3... Done\n",
      "  Validating... Done\n",
      "Epoch:4... Done\n",
      "  Validating... Done\n",
      "Epoch:5... Done\n",
      "  Validating... Done\n",
      "Epoch:6... Done\n",
      "  Validating... Done\n",
      "Epoch:7... Done\n",
      "  Validating... Done\n",
      "Epoch:8... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 7\n",
      "Epoch:9... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 7\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b229eda3934b7ab610786f314a7cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_auroc_macro</td><td>▁█</td></tr><tr><td>val_hamming_loss_macro</td><td>█▁</td></tr><tr><td>val_loss</td><td>█▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.65</td></tr><tr><td>test_hamming_loss_macro</td><td>0.20528</td></tr><tr><td>train_auroc_macro</td><td>0.76365</td></tr><tr><td>train_hamming_loss_macro</td><td>0.1553</td></tr><tr><td>train_loss</td><td>0.3783</td></tr><tr><td>val_auroc_macro</td><td>0.66768</td></tr><tr><td>val_hamming_loss_macro</td><td>0.21281</td></tr><tr><td>val_loss</td><td>0.4883</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lunar-galaxy-381</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/39yxjjah\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/39yxjjah</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220620_153016-39yxjjah/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+--------------------+-------------+\n",
      "|  mode | #epoch |   loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "| train |   0    | 69.7204 |       0.6972       |    0.5023   |\n",
      "| train |   1    |  1.1146 |         -          |      -      |\n",
      "| train |   2    |  0.5757 |         -          |      -      |\n",
      "| train |   3    |  0.5387 |         -          |      -      |\n",
      "| train |   4    |  0.4972 |         -          |      -      |\n",
      "| train |   5    |  0.4605 |         -          |      -      |\n",
      "| train |   6    |  0.4349 |         -          |      -      |\n",
      "| train |   7    |  0.413  |         -          |      -      |\n",
      "| train |   8    |  0.3953 |         -          |      -      |\n",
      "| train |   9    |  0.3783 |       0.1553       |    0.7637   |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 7.5089 |       0.7025       |    0.4908   |      0/10      |\n",
      "| val  |   1    | 0.5965 |         -          |      -      |      0/10      |\n",
      "| val  |   2    | 0.5676 |         -          |      -      |      0/10      |\n",
      "| val  |   3    | 0.5368 |         -          |      -      |      0/10      |\n",
      "| val  |   4    | 0.5023 |         -          |      -      |      0/10      |\n",
      "| val  |   5    | 0.4815 |         -          |      -      |      0/10      |\n",
      "| val  |   6    | 0.475  |         -          |      -      |      0/10      |\n",
      "| val  |   7    | 0.4721 |         -          |      -      |      0/10      |\n",
      "| val  |   8    | 0.4811 |         -          |      -      |      1/10      |\n",
      "| val  |   9    | 0.4883 |       0.2128       |    0.6677   |      2/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   7    |  -   |       0.2053       |     0.65    |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "---- Finished evaluating configuration with score: 0.4721497098604838\n",
      "---- Evaluating configuration... \n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/wandb/run-20220620_153111-34rz41a0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/34rz41a0\" target=\"_blank\">bright-bee-382</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Done\n",
      "Epoch:2... Done\n",
      "  Validating... Done\n",
      "Epoch:3... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 2\n",
      "Epoch:4... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 2\n",
      "Epoch:5... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 3 out of 10---------------------- best epoch currently 2\n",
      "Epoch:6... Done\n",
      "  Validating... Done\n",
      "Epoch:7... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 6\n",
      "Epoch:8... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 6\n",
      "Epoch:9... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "-----------------------------EarlyStopping counter: 3 out of 10---------------------- best epoch currently 6\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dabc3efb13294effbeffca90f50fec2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_auroc_macro</td><td>▁█</td></tr><tr><td>val_hamming_loss_macro</td><td>█▁</td></tr><tr><td>val_loss</td><td>█▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.67771</td></tr><tr><td>test_hamming_loss_macro</td><td>0.2044</td></tr><tr><td>train_auroc_macro</td><td>0.86203</td></tr><tr><td>train_hamming_loss_macro</td><td>0.14877</td></tr><tr><td>train_loss</td><td>0.35927</td></tr><tr><td>val_auroc_macro</td><td>0.70562</td></tr><tr><td>val_hamming_loss_macro</td><td>0.20766</td></tr><tr><td>val_loss</td><td>0.71872</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">bright-bee-382</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/34rz41a0\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/34rz41a0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220620_153111-34rz41a0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+--------------------+-------------+\n",
      "|  mode | #epoch |   loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "| train |   0    | 69.7271 |       0.6972       |    0.5134   |\n",
      "| train |   1    |  1.5067 |         -          |      -      |\n",
      "| train |   2    |  0.5203 |         -          |      -      |\n",
      "| train |   3    |  0.4862 |         -          |      -      |\n",
      "| train |   4    |  0.4652 |         -          |      -      |\n",
      "| train |   5    |  0.4452 |         -          |      -      |\n",
      "| train |   6    |  0.4474 |         -          |      -      |\n",
      "| train |   7    |  0.4143 |         -          |      -      |\n",
      "| train |   8    |  0.3805 |         -          |      -      |\n",
      "| train |   9    |  0.3593 |       0.1488       |    0.862    |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |   loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 45.3897 |       0.7025       |    0.5228   |      0/10      |\n",
      "| val  |   1    |  0.5125 |         -          |      -      |      0/10      |\n",
      "| val  |   2    |  0.4962 |         -          |      -      |      0/10      |\n",
      "| val  |   3    |  0.6571 |         -          |      -      |      1/10      |\n",
      "| val  |   4    |  0.5507 |         -          |      -      |      2/10      |\n",
      "| val  |   5    |  0.5039 |         -          |      -      |      3/10      |\n",
      "| val  |   6    |  0.4774 |         -          |      -      |      0/10      |\n",
      "| val  |   7    |  0.5261 |         -          |      -      |      1/10      |\n",
      "| val  |   8    |  0.4885 |         -          |      -      |      2/10      |\n",
      "| val  |   9    |  0.7187 |       0.2077       |    0.7056   |      3/10      |\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   6    |  -   |       0.2044       |    0.6777   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "---- Finished evaluating configuration with score: 0.47738895813624066\n",
      "---- Evaluating configuration... \n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/wandb/run-20220620_153206-n1hujhqe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/n1hujhqe\" target=\"_blank\">breezy-armadillo-383</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Done\n",
      "Epoch:2... Done\n",
      "  Validating... Done\n",
      "Epoch:3... Done\n",
      "  Validating... Done\n",
      "Epoch:4... Done\n",
      "  Validating... Done\n",
      "Epoch:5... Done\n",
      "  Validating... Done\n",
      "Epoch:6... Done\n",
      "  Validating... Done\n",
      "Epoch:7... Done\n",
      "  Validating... Done\n",
      "Epoch:8... Done\n",
      "  Validating... Done\n",
      "Epoch:9... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c03c2887cfa493688474762d3a8fce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_auroc_macro</td><td>▁█</td></tr><tr><td>val_hamming_loss_macro</td><td>█▁</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.56199</td></tr><tr><td>test_hamming_loss_macro</td><td>0.46561</td></tr><tr><td>train_auroc_macro</td><td>0.57193</td></tr><tr><td>train_hamming_loss_macro</td><td>0.22776</td></tr><tr><td>train_loss</td><td>0.68725</td></tr><tr><td>val_auroc_macro</td><td>0.59184</td></tr><tr><td>val_hamming_loss_macro</td><td>0.46208</td></tr><tr><td>val_loss</td><td>0.68935</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">breezy-armadillo-383</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/n1hujhqe\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/n1hujhqe</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220620_153206-n1hujhqe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+--------------------+-------------+\n",
      "|  mode | #epoch |   loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "| train |   0    | 19.2202 |       0.6972       |    0.5011   |\n",
      "| train |   1    |  1.9244 |         -          |      -      |\n",
      "| train |   2    |  1.3903 |         -          |      -      |\n",
      "| train |   3    |   1.09  |         -          |      -      |\n",
      "| train |   4    |  0.918  |         -          |      -      |\n",
      "| train |   5    |  0.8181 |         -          |      -      |\n",
      "| train |   6    |  0.7597 |         -          |      -      |\n",
      "| train |   7    |  0.724  |         -          |      -      |\n",
      "| train |   8    |  0.7015 |         -          |      -      |\n",
      "| train |   9    |  0.6873 |       0.2278       |    0.5719   |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 2.2839 |       0.7025       |    0.5515   |      0/10      |\n",
      "| val  |   1    | 1.625  |         -          |      -      |      0/10      |\n",
      "| val  |   2    | 1.2293 |         -          |      -      |      0/10      |\n",
      "| val  |   3    | 1.0036 |         -          |      -      |      0/10      |\n",
      "| val  |   4    | 0.8733 |         -          |      -      |      0/10      |\n",
      "| val  |   5    | 0.7956 |         -          |      -      |      0/10      |\n",
      "| val  |   6    | 0.7493 |         -          |      -      |      0/10      |\n",
      "| val  |   7    | 0.7199 |         -          |      -      |      0/10      |\n",
      "| val  |   8    | 0.7009 |         -          |      -      |      0/10      |\n",
      "| val  |   9    | 0.6893 |       0.4621       |    0.5918   |      0/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   9    |  -   |       0.4656       |    0.562    |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "---- Finished evaluating configuration with score: 0.689349909623464\n",
      "---- Evaluating configuration... \n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/wandb/run-20220620_153309-32yj9ayp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/32yj9ayp\" target=\"_blank\">bumbling-sponge-384</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Done\n",
      "Epoch:2... Done\n",
      "  Validating... Done\n",
      "Epoch:3... Done\n",
      "  Validating... Done\n",
      "Epoch:4... Done\n",
      "  Validating... Done\n",
      "Epoch:5... Done\n",
      "  Validating... Done\n",
      "Epoch:6... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 5\n",
      "Epoch:7... Done\n",
      "  Validating... Done\n",
      "Epoch:8... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 7\n",
      "Epoch:9... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 7\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794bc9397f184b079ba012c1ca5f3fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▄▄▃▃▂▂▂▁▁</td></tr><tr><td>val_auroc_macro</td><td>▁█</td></tr><tr><td>val_hamming_loss_macro</td><td>█▁</td></tr><tr><td>val_loss</td><td>█▅▄▃▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.68214</td></tr><tr><td>test_hamming_loss_macro</td><td>0.19746</td></tr><tr><td>train_auroc_macro</td><td>0.77377</td></tr><tr><td>train_hamming_loss_macro</td><td>0.18192</td></tr><tr><td>train_loss</td><td>0.3922</td></tr><tr><td>val_auroc_macro</td><td>0.69344</td></tr><tr><td>val_hamming_loss_macro</td><td>0.20287</td></tr><tr><td>val_loss</td><td>0.45262</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">bumbling-sponge-384</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/32yj9ayp\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/32yj9ayp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220620_153309-32yj9ayp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+-------------+\n",
      "|  mode | #epoch |  loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "| train |   0    | 0.6277 |       0.2865       |    0.5128   |\n",
      "| train |   1    | 0.5021 |         -          |      -      |\n",
      "| train |   2    | 0.4823 |         -          |      -      |\n",
      "| train |   3    | 0.4675 |         -          |      -      |\n",
      "| train |   4    | 0.4504 |         -          |      -      |\n",
      "| train |   5    | 0.4344 |         -          |      -      |\n",
      "| train |   6    | 0.4225 |         -          |      -      |\n",
      "| train |   7    | 0.4117 |         -          |      -      |\n",
      "| train |   8    | 0.4019 |         -          |      -      |\n",
      "| train |   9    | 0.3922 |       0.1819       |    0.7738   |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 0.5212 |       0.2297       |    0.537    |      0/10      |\n",
      "| val  |   1    | 0.4944 |         -          |      -      |      0/10      |\n",
      "| val  |   2    | 0.482  |         -          |      -      |      0/10      |\n",
      "| val  |   3    | 0.4686 |         -          |      -      |      0/10      |\n",
      "| val  |   4    | 0.4605 |         -          |      -      |      0/10      |\n",
      "| val  |   5    | 0.4543 |         -          |      -      |      0/10      |\n",
      "| val  |   6    | 0.4547 |         -          |      -      |      1/10      |\n",
      "| val  |   7    | 0.4526 |         -          |      -      |      0/10      |\n",
      "| val  |   8    | 0.4533 |         -          |      -      |      1/10      |\n",
      "| val  |   9    | 0.4526 |       0.2029       |    0.6934   |      2/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   7    |  -   |       0.1975       |    0.6821   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "---- Finished evaluating configuration with score: 0.4525774121284485\n",
      "---- Evaluating configuration... \n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/wandb/run-20220620_153404-2r5m2mug</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/2r5m2mug\" target=\"_blank\">gentle-fire-385</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Done\n",
      "Epoch:2... Done\n",
      "  Validating... Done\n",
      "Epoch:3... Done\n",
      "  Validating... Done\n",
      "Epoch:4... Done\n",
      "  Validating... Done\n",
      "Epoch:5... Done\n",
      "  Validating... Done\n",
      "Epoch:6... Done\n",
      "  Validating... Done\n",
      "Epoch:7... Done\n",
      "  Validating... Done\n",
      "Epoch:8... Done\n",
      "  Validating... Done\n",
      "Epoch:9... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9954a86bd524dbd81884fe81e7d4ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▆▂▂▁▁▁▁▁▁</td></tr><tr><td>val_auroc_macro</td><td>▁█</td></tr><tr><td>val_hamming_loss_macro</td><td>█▁</td></tr><tr><td>val_loss</td><td>█▄▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.53204</td></tr><tr><td>test_hamming_loss_macro</td><td>0.69599</td></tr><tr><td>train_auroc_macro</td><td>0.52838</td></tr><tr><td>train_hamming_loss_macro</td><td>0.69564</td></tr><tr><td>train_loss</td><td>1.64894</td></tr><tr><td>val_auroc_macro</td><td>0.52946</td></tr><tr><td>val_hamming_loss_macro</td><td>0.70214</td></tr><tr><td>val_loss</td><td>1.55851</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">gentle-fire-385</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/2r5m2mug\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/2r5m2mug</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220620_153404-2r5m2mug/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+--------------------+-------------+\n",
      "|  mode | #epoch |   loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "| train |   0    | 69.7071 |       0.6972       |    0.4943   |\n",
      "| train |   1    | 48.3088 |         -          |      -      |\n",
      "| train |   2    | 14.6907 |         -          |      -      |\n",
      "| train |   3    |  6.6439 |         -          |      -      |\n",
      "| train |   4    |  5.0357 |         -          |      -      |\n",
      "| train |   5    |  3.9442 |         -          |      -      |\n",
      "| train |   6    |  3.1283 |         -          |      -      |\n",
      "| train |   7    |  2.4999 |         -          |      -      |\n",
      "| train |   8    |  2.016  |         -          |      -      |\n",
      "| train |   9    |  1.6489 |       0.6956       |    0.5284   |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |   loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "| val  |   0    |  68.301 |       0.7025       |    0.4961   |      0/10      |\n",
      "| val  |   1    | 26.7382 |         -          |      -      |      0/10      |\n",
      "| val  |   2    |   7.95  |         -          |      -      |      0/10      |\n",
      "| val  |   3    |  5.8473 |         -          |      -      |      0/10      |\n",
      "| val  |   4    |  4.5527 |         -          |      -      |      0/10      |\n",
      "| val  |   5    |  3.6023 |         -          |      -      |      0/10      |\n",
      "| val  |   6    |  2.876  |         -          |      -      |      0/10      |\n",
      "| val  |   7    |  2.3172 |         -          |      -      |      0/10      |\n",
      "| val  |   8    |  1.8855 |         -          |      -      |      0/10      |\n",
      "| val  |   9    |  1.5585 |       0.7021       |    0.5295   |      0/10      |\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   9    |  -   |       0.696        |    0.532    |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "---- Finished evaluating configuration with score: 1.558508296807607\n",
      "---- Evaluating configuration... \n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/wandb/run-20220620_153459-1r8dqzya</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/1r8dqzya\" target=\"_blank\">noble-breeze-386</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Done\n",
      "Epoch:2... Done\n",
      "  Validating... Done\n",
      "Epoch:3... Done\n",
      "  Validating... Done\n",
      "Epoch:4... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 3\n",
      "Epoch:5... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 3\n",
      "Epoch:6... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 3 out of 10---------------------- best epoch currently 3\n",
      "Epoch:7... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 4 out of 10---------------------- best epoch currently 3\n",
      "Epoch:8... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 5 out of 10---------------------- best epoch currently 3\n",
      "Epoch:9... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "-----------------------------EarlyStopping counter: 6 out of 10---------------------- best epoch currently 3\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda77dc1ed21473f906733aea0f78f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▄▁▁▁▁▁▁▁▁</td></tr><tr><td>val_auroc_macro</td><td>▁█</td></tr><tr><td>val_hamming_loss_macro</td><td>█▁</td></tr><tr><td>val_loss</td><td>█▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.68014</td></tr><tr><td>test_hamming_loss_macro</td><td>0.20484</td></tr><tr><td>train_auroc_macro</td><td>0.93145</td></tr><tr><td>train_hamming_loss_macro</td><td>0.07467</td></tr><tr><td>train_loss</td><td>0.20352</td></tr><tr><td>val_auroc_macro</td><td>0.7093</td></tr><tr><td>val_hamming_loss_macro</td><td>0.22128</td></tr><tr><td>val_loss</td><td>1.2204</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">noble-breeze-386</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/1r8dqzya\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/1r8dqzya</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220620_153459-1r8dqzya/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+--------------------+-------------+\n",
      "|  mode | #epoch |   loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "| train |   0    |  69.674 |       0.6972       |    0.5095   |\n",
      "| train |   1    | 25.7964 |         -          |      -      |\n",
      "| train |   2    |  0.462  |         -          |      -      |\n",
      "| train |   3    |  0.4177 |         -          |      -      |\n",
      "| train |   4    |  0.3791 |         -          |      -      |\n",
      "| train |   5    |  0.3396 |         -          |      -      |\n",
      "| train |   6    |  0.2914 |         -          |      -      |\n",
      "| train |   7    |  0.2641 |         -          |      -      |\n",
      "| train |   8    |  0.2299 |         -          |      -      |\n",
      "| train |   9    |  0.2035 |       0.0747       |    0.9315   |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |   loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 70.0417 |       0.7025       |    0.4997   |      0/10      |\n",
      "| val  |   1    |  0.4882 |         -          |      -      |      0/10      |\n",
      "| val  |   2    |  0.4856 |         -          |      -      |      0/10      |\n",
      "| val  |   3    |  0.4762 |         -          |      -      |      0/10      |\n",
      "| val  |   4    |  0.5182 |         -          |      -      |      1/10      |\n",
      "| val  |   5    |  0.5251 |         -          |      -      |      2/10      |\n",
      "| val  |   6    |  0.5915 |         -          |      -      |      3/10      |\n",
      "| val  |   7    |  0.6721 |         -          |      -      |      4/10      |\n",
      "| val  |   8    |  1.0027 |         -          |      -      |      5/10      |\n",
      "| val  |   9    |  1.2204 |       0.2213       |    0.7093   |      6/10      |\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   3    |  -   |       0.2048       |    0.6801   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "---- Finished evaluating configuration with score: 0.4762229224046071\n",
      "Best overall configuration: \n",
      "config: Configuration(values={\n",
      "  'embedding_size': 1383,\n",
      "  'instance_branch_layers': 1,\n",
      "  'instance_branch_nodes_per_layer': 1006,\n",
      "  'learning_rate': 0.0001616151642875306,\n",
      "  'target_branch_layers': 1,\n",
      "  'target_branch_nodes_per_layer': 1138,\n",
      "})\n",
      "  |  budget: 10  |  score: 0.4525774121284485\n",
      "{'model_dir': './random_search/20_06_2022__15_27_16//20_06_2022__15_33_09/model.pt', 'config': {'validation_setting': 'B', 'enable_dot_product_version': True, 'problem_mode': 'classification', 'learning_rate': 0.0001616151642875306, 'decay': 0, 'batch_norm': 0, 'dropout_rate': 0, 'momentum': 0.9, 'weighted_loss': False, 'compute_mode': 'cuda:1', 'num_workers': 8, 'train_batchsize': 512, 'val_batchsize': 512, 'num_epochs': 10, 'use_early_stopping': True, 'patience': 10, 'evaluate_train': True, 'evaluate_val': True, 'verbose': True, 'results_verbose': False, 'return_results_per_target': False, 'metric_to_optimize_early_stopping': 'loss', 'metric_to_optimize_best_epoch_selection': 'loss', 'instance_branch_architecture': 'MLP', 'target_branch_architecture': 'MLP', 'use_instance_features': False, 'use_target_features': False, 'use_tensorboard_logger': False, 'wandb_project_name': 'DeepMTP_v2', 'wandb_project_entity': 'diliadis', 'results_path': './random_search/20_06_2022__15_27_16/', 'experiment_name': 'best_model', 'save_model': True, 'instance_branch_input_dim': 103, 'target_branch_input_dim': 14, 'eval_every_n_epochs': 10, 'load_pretrained_model': False, 'pretrained_model_path': '', 'instance_train_transforms': None, 'instance_inference_transforms': None, 'target_train_transforms': None, 'target_inference_transforms': None, 'running_hpo': True, 'metrics': ['hamming_loss', 'auroc'], 'metrics_average': ['macro'], 'embedding_size': 1383, 'instance_branch_nodes_per_layer': 1006, 'instance_branch_layers': 1, 'instance_branch_nodes_reducing_factor': 2, 'target_branch_nodes_per_layer': 1138, 'target_branch_layers': 1, 'target_branch_nodes_reducing_factor': 2, 'budget': 10, 'budget_int': 10, 'actuall_budget': 10, 'experiment_dir': './random_search/20_06_2022__15_27_16/20_06_2022__15_33_09'}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_overall_config = hb.run_optimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the best model and generate predictions for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = DeepMTP(best_overall_config.info['config'], checkpoint_dir=best_overall_config.info['model_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_model = DeepMTP(best_overall_config.info['config'], best_overall_config.info['model_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_results = best_model.predict(test, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('test_deepMTP_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f5380de0ecd406fe60ee993d69ff633b6383f3524952a51a8c99019a05ba7a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
