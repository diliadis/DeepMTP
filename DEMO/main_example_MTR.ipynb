{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimitriosi/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.chdir('../')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from DeepMTP.dataset import load_process_MLC, load_process_MTR, load_process_DP, process_dummy_MLC, process_dummy_MTR, process_dummy_DP, load_process_MC, load_process_MTL\n",
    "from DeepMTP.utils.data_utils import data_process, BaseDataset\n",
    "from DeepMTP.utils.tests import check_mlc_results, check_mtr_results, check_dp_results, check_mtl_results\n",
    "from DeepMTP.main import DeepMTP\n",
    "from DeepMTP.utils.utils import generate_config\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate regression\n",
    "<img src=\"../images/mtr_example.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load-process-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done\n",
      "Interaction file: 2d numpy array format detected\n",
      "Interaction file: checking format consistency... Passed\n",
      "Interaction file: checking instance id format consistency... Passed\n",
      "Interaction file: checking target id type consistency... Passed\n",
      "\n",
      "Interaction file: checking target variable type consistency... Passed\n",
      "Automatically detected type of target variable type: real-valued\n",
      "\n",
      "-- Test set was not provided, could not detect if novel instances exist or not \n",
      "-- Test set was not provided, could not detect if novel targets exist or not \n",
      "\n",
      "Instance features file: processing features... Done\n",
      "\n",
      "Cross input consistency for (numpy) interaction data and instance features checks out\n",
      "-- Same instance ids in the interaction and features files for the train set\n",
      "\n",
      "Splitting train to train-test according to validation setting B... Done\n",
      "Splitting train to train-val according to validation setting B... Done\n",
      "Checking if MTR splitting results are valid... Done\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "data = load_process_MTR(dataset_name='enb', features_type='numpy')\n",
    "# process and split\n",
    "train, val, test, data_info = data_process(data, validation_setting='B', verbose=True)\n",
    "# sanity check\n",
    "check_mtr_results(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detected_validation_setting': 'B',\n",
       " 'detected_problem_mode': 'regression',\n",
       " 'instance_branch_input_dim': 8,\n",
       " 'target_branch_input_dim': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure and train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = generate_config(    \n",
    "    instance_branch_input_dim = data_info['instance_branch_input_dim'],\n",
    "    target_branch_input_dim = data_info['target_branch_input_dim'],\n",
    "    validation_setting = data_info['detected_validation_setting'],\n",
    "    general_architecture_version = 'dot_product',\n",
    "    problem_mode = data_info['detected_problem_mode'],\n",
    "    learning_rate = 0.001,\n",
    "    decay = 0,\n",
    "    batch_norm = False,\n",
    "    dropout_rate = 0,\n",
    "    momentum = 0.9,\n",
    "    weighted_loss = False,\n",
    "    compute_mode = 'cuda:1',\n",
    "    train_batchsize = 512,\n",
    "    val_batchsize = 512,\n",
    "    num_epochs = 50,\n",
    "    num_workers = 8,\n",
    "    metrics = ['RMSE', 'R2'],\n",
    "    metrics_average = ['macro'],\n",
    "    patience = 10,\n",
    "\n",
    "    evaluate_train = True,\n",
    "    evaluate_val = True,\n",
    "\n",
    "    verbose = True,\n",
    "    results_verbose = False,\n",
    "    use_early_stopping = True,\n",
    "    use_tensorboard_logger = True,\n",
    "    wandb_project_name = 'DeepMTP_v2',\n",
    "    wandb_project_entity = 'diliadis',\n",
    "    metric_to_optimize_early_stopping = 'loss',\n",
    "    metric_to_optimize_best_epoch_selection = 'loss',\n",
    "\n",
    "    instance_branch_architecture = 'MLP',\n",
    "    use_instance_features = False,\n",
    "    instance_branch_params = {\n",
    "        'instance_branch_nodes_reducing_factor': 2,\n",
    "        'instance_branch_nodes_per_layer': [100, 100],\n",
    "        'instance_branch_layers': None,\n",
    "        # 'instance_branch_conv_architecture': 'resnet',\n",
    "        # 'instance_branch_conv_architecture_version': 'resnet101',\n",
    "        # 'instance_branch_conv_architecture_dense_layers': 1,\n",
    "        # 'instance_branch_conv_architecture_last_layer_trained': 'last',\n",
    "    },\n",
    "\n",
    "    target_branch_architecture = 'MLP',\n",
    "    use_target_features = False,\n",
    "    target_branch_params = {\n",
    "        'target_branch_nodes_reducing_factor': 2,\n",
    "        'target_branch_nodes_per_layer': [132, 100],\n",
    "        'target_branch_layers': None,\n",
    "        # 'target_branch_conv_architecture': 'resnet',\n",
    "        # 'target_branch_conv_architecture_version': 'resnet101',\n",
    "        # 'target_branch_conv_architecture_dense_layers': 1,\n",
    "        # 'target_branch_conv_architecture_last_layer_trained': 'last',\n",
    "    },\n",
    "\n",
    "    embedding_size = 30,\n",
    "    comb_mlp_nodes_reducing_factor = 2,\n",
    "    comb_mlp_nodes_per_layer = [2048, 2048, 2048],\n",
    "    comb_mlp_layers = None, \n",
    "\n",
    "    save_model = True,\n",
    "\n",
    "    eval_every_n_epochs = 10,\n",
    "\n",
    "    additional_info = {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdiliadis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220529_193646-1wpfr4wk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/1wpfr4wk\" target=\"_blank\">exalted-plasma-97</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Done\n",
      "Epoch:2... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 1\n",
      "Epoch:3... Done\n",
      "  Validating... Done\n",
      "Epoch:4... Done\n",
      "  Validating... Done\n",
      "Epoch:5... Done\n",
      "  Validating... Done\n",
      "Epoch:6... Done\n",
      "  Validating... Done\n",
      "Epoch:7... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 6\n",
      "Epoch:8... Done\n",
      "  Validating... Done\n",
      "Epoch:9... Done\n",
      "  Validating... Done\n",
      "Epoch:10... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 9\n",
      "Epoch:11... Done\n",
      "  Validating... Done\n",
      "Epoch:12... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 11\n",
      "Epoch:13... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 11\n",
      "Epoch:14... Done\n",
      "  Validating... Done\n",
      "Epoch:15... Done\n",
      "  Validating... Done\n",
      "Epoch:16... Done\n",
      "  Validating... Done\n",
      "Epoch:17... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 16\n",
      "Epoch:18... Done\n",
      "  Validating... Done\n",
      "Epoch:19... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 18\n",
      "Epoch:20... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 18\n",
      "Epoch:21... Done\n",
      "  Validating... Done\n",
      "Epoch:22... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 21\n",
      "Epoch:23... Done\n",
      "  Validating... Done\n",
      "Epoch:24... Done\n",
      "  Validating... Done\n",
      "Epoch:25... Done\n",
      "  Validating... Done\n",
      "Epoch:26... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 25\n",
      "Epoch:27... Done\n",
      "  Validating... Done\n",
      "Epoch:28... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 27\n",
      "Epoch:29... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 27\n",
      "Epoch:30... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:31... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 30\n",
      "Epoch:32... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 30\n",
      "Epoch:33... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 3 out of 10---------------------- best epoch currently 30\n",
      "Epoch:34... Done\n",
      "  Validating... Done\n",
      "Epoch:35... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 34\n",
      "Epoch:36... Done\n",
      "  Validating... Done\n",
      "Epoch:37... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 36\n",
      "Epoch:38... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 36\n",
      "Epoch:39... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 3 out of 10---------------------- best epoch currently 36\n",
      "Epoch:40... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:41... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 40\n",
      "Epoch:42... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 40\n",
      "Epoch:43... Done\n",
      "  Validating... Done\n",
      "Epoch:44... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 43\n",
      "Epoch:45... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 43\n",
      "Epoch:46... Done\n",
      "  Validating... Done\n",
      "Epoch:47... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 46\n",
      "Epoch:48... Done\n",
      "  Validating... Done\n",
      "Epoch:49... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 48\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_R2_macro</td><td>▁</td></tr><tr><td>test_RMSE_macro</td><td>▁</td></tr><tr><td>train_R2_macro</td><td>▁█████</td></tr><tr><td>train_RMSE_macro</td><td>█▁▂▂▃▂</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_R2_macro</td><td>▁▇████</td></tr><tr><td>val_RMSE_macro</td><td>█▂▂▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▄▃▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_R2_macro</td><td>0.77066</td></tr><tr><td>test_RMSE_macro</td><td>4.7373</td></tr><tr><td>train_R2_macro</td><td>0.75895</td></tr><tr><td>train_RMSE_macro</td><td>13.46407</td></tr><tr><td>train_loss</td><td>21.58333</td></tr><tr><td>val_R2_macro</td><td>0.70777</td></tr><tr><td>val_RMSE_macro</td><td>5.04086</td></tr><tr><td>val_loss</td><td>25.42384</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">exalted-plasma-97</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/1wpfr4wk\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/1wpfr4wk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220529_193646-1wpfr4wk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----------+------------+----------+\n",
      "|  mode | #epoch |   loss   | RMSE_macro | R2_macro |\n",
      "+-------+--------+----------+------------+----------+\n",
      "| train |   0    | 278.4611 |  17.4835   | -2.3584  |\n",
      "| train |   1    | 192.2865 |     -      |    -     |\n",
      "| train |   2    | 174.5429 |     -      |    -     |\n",
      "| train |   3    | 129.0591 |     -      |    -     |\n",
      "| train |   4    | 119.669  |     -      |    -     |\n",
      "| train |   5    | 91.8755  |     -      |    -     |\n",
      "| train |   6    | 90.4502  |     -      |    -     |\n",
      "| train |   7    | 69.5529  |     -      |    -     |\n",
      "| train |   8    | 60.3253  |     -      |    -     |\n",
      "| train |   9    | 49.0193  |     -      |    -     |\n",
      "| train |   10   | 39.7001  |  12.4966   |  0.596   |\n",
      "| train |   11   | 34.7791  |     -      |    -     |\n",
      "| train |   12   | 36.3757  |     -      |    -     |\n",
      "| train |   13   | 35.0463  |     -      |    -     |\n",
      "| train |   14   | 38.4754  |     -      |    -     |\n",
      "| train |   15   | 37.1733  |     -      |    -     |\n",
      "| train |   16   | 33.0876  |     -      |    -     |\n",
      "| train |   17   | 28.4181  |     -      |    -     |\n",
      "| train |   18   | 30.7032  |     -      |    -     |\n",
      "| train |   19   | 31.9755  |     -      |    -     |\n",
      "| train |   20   | 30.8884  |  13.0779   |  0.6845  |\n",
      "| train |   21   | 32.2098  |     -      |    -     |\n",
      "| train |   22   | 30.3268  |     -      |    -     |\n",
      "| train |   23   | 28.3147  |     -      |    -     |\n",
      "| train |   24   | 28.4932  |     -      |    -     |\n",
      "| train |   25   | 30.4923  |     -      |    -     |\n",
      "| train |   26   | 28.3084  |     -      |    -     |\n",
      "| train |   27   | 28.9028  |     -      |    -     |\n",
      "| train |   28   |  25.845  |     -      |    -     |\n",
      "| train |   29   | 26.8876  |     -      |    -     |\n",
      "| train |   30   | 26.4615  |  13.2778   |  0.7231  |\n",
      "| train |   31   | 25.3096  |     -      |    -     |\n",
      "| train |   32   | 26.1278  |     -      |    -     |\n",
      "| train |   33   | 25.1604  |     -      |    -     |\n",
      "| train |   34   | 25.7959  |     -      |    -     |\n",
      "| train |   35   | 26.2528  |     -      |    -     |\n",
      "| train |   36   | 26.6254  |     -      |    -     |\n",
      "| train |   37   | 25.8442  |     -      |    -     |\n",
      "| train |   38   | 26.0085  |     -      |    -     |\n",
      "| train |   39   | 29.6245  |     -      |    -     |\n",
      "| train |   40   | 28.1589  |  13.7658   |  0.7061  |\n",
      "| train |   41   | 26.1899  |     -      |    -     |\n",
      "| train |   42   | 26.2346  |     -      |    -     |\n",
      "| train |   43   | 23.9232  |     -      |    -     |\n",
      "| train |   44   | 24.7399  |     -      |    -     |\n",
      "| train |   45   | 23.9592  |     -      |    -     |\n",
      "| train |   46   | 24.1721  |     -      |    -     |\n",
      "| train |   47   | 23.7514  |     -      |    -     |\n",
      "| train |   48   |  24.352  |     -      |    -     |\n",
      "| train |   49   | 21.5833  |  13.4641   |  0.7589  |\n",
      "+-------+--------+----------+------------+----------+\n",
      "====================\n",
      "+------+--------+----------+------------+----------+----------------+\n",
      "| mode | #epoch |   loss   | RMSE_macro | R2_macro | early_stopping |\n",
      "+------+--------+----------+------------+----------+----------------+\n",
      "| val  |   0    | 295.623  |  17.1866   | -2.3995  |      0/10      |\n",
      "| val  |   1    | 121.4859 |     -      |    -     |      0/10      |\n",
      "| val  |   2    | 132.4607 |     -      |    -     |      1/10      |\n",
      "| val  |   3    | 112.4158 |     -      |    -     |      0/10      |\n",
      "| val  |   4    | 103.5934 |     -      |    -     |      0/10      |\n",
      "| val  |   5    | 83.1733  |     -      |    -     |      0/10      |\n",
      "| val  |   6    | 67.0863  |     -      |    -     |      0/10      |\n",
      "| val  |   7    | 78.3864  |     -      |    -     |      1/10      |\n",
      "| val  |   8    | 41.8312  |     -      |    -     |      0/10      |\n",
      "| val  |   9    | 35.3594  |     -      |    -     |      0/10      |\n",
      "| val  |   10   | 45.0798  |   6.7039   |  0.4805  |      1/10      |\n",
      "| val  |   11   | 34.6476  |     -      |    -     |      0/10      |\n",
      "| val  |   12   | 38.2971  |     -      |    -     |      1/10      |\n",
      "| val  |   13   |   35.2   |     -      |    -     |      2/10      |\n",
      "| val  |   14   |  34.547  |     -      |    -     |      0/10      |\n",
      "| val  |   15   | 32.6343  |     -      |    -     |      0/10      |\n",
      "| val  |   16   | 30.2911  |     -      |    -     |      0/10      |\n",
      "| val  |   17   | 37.7425  |     -      |    -     |      1/10      |\n",
      "| val  |   18   | 29.5911  |     -      |    -     |      0/10      |\n",
      "| val  |   19   | 30.2383  |     -      |    -     |      1/10      |\n",
      "| val  |   20   | 33.7298  |   5.8077   |  0.6129  |      2/10      |\n",
      "| val  |   21   | 28.9286  |     -      |    -     |      0/10      |\n",
      "| val  |   22   |  30.234  |     -      |    -     |      1/10      |\n",
      "| val  |   23   | 28.3731  |     -      |    -     |      0/10      |\n",
      "| val  |   24   | 28.2141  |     -      |    -     |      0/10      |\n",
      "| val  |   25   | 27.9198  |     -      |    -     |      0/10      |\n",
      "| val  |   26   | 28.6647  |     -      |    -     |      1/10      |\n",
      "| val  |   27   | 26.9649  |     -      |    -     |      0/10      |\n",
      "| val  |   28   | 28.4134  |     -      |    -     |      1/10      |\n",
      "| val  |   29   | 27.3894  |     -      |    -     |      2/10      |\n",
      "| val  |   30   | 26.1606  |   5.1123   |  0.6991  |      0/10      |\n",
      "| val  |   31   | 28.8541  |     -      |    -     |      1/10      |\n",
      "| val  |   32   | 26.1766  |     -      |    -     |      2/10      |\n",
      "| val  |   33   | 27.3782  |     -      |    -     |      3/10      |\n",
      "| val  |   34   | 25.8336  |     -      |    -     |      0/10      |\n",
      "| val  |   35   | 26.7668  |     -      |    -     |      1/10      |\n",
      "| val  |   36   | 25.4406  |     -      |    -     |      0/10      |\n",
      "| val  |   37   | 30.9396  |     -      |    -     |      1/10      |\n",
      "| val  |   38   | 25.4577  |     -      |    -     |      2/10      |\n",
      "| val  |   39   | 30.8152  |     -      |    -     |      3/10      |\n",
      "| val  |   40   | 24.1335  |   4.9108   |  0.7225  |      0/10      |\n",
      "| val  |   41   | 25.7007  |     -      |    -     |      1/10      |\n",
      "| val  |   42   | 24.3521  |     -      |    -     |      2/10      |\n",
      "| val  |   43   | 23.9329  |     -      |    -     |      0/10      |\n",
      "| val  |   44   | 26.5948  |     -      |    -     |      1/10      |\n",
      "| val  |   45   |  24.004  |     -      |    -     |      2/10      |\n",
      "| val  |   46   | 23.8207  |     -      |    -     |      0/10      |\n",
      "| val  |   47   | 24.9197  |     -      |    -     |      1/10      |\n",
      "| val  |   48   | 23.5794  |     -      |    -     |      0/10      |\n",
      "| val  |   49   | 25.4238  |   5.0409   |  0.7078  |      1/10      |\n",
      "+------+--------+----------+------------+----------+----------------+\n",
      "====================\n",
      "+------+--------+------+------------+----------+\n",
      "| mode | #epoch | loss | RMSE_macro | R2_macro |\n",
      "+------+--------+------+------------+----------+\n",
      "| test |   48   |  -   |   4.7373   |  0.7707  |\n",
      "+------+--------+------+------------+----------+\n",
      "Saving the best model... Done\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "model = DeepMTP(config)\n",
    "# train, validate, test\n",
    "validation_results = model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating  performance... Done\n"
     ]
    }
   ],
   "source": [
    "# generate predictions from the trained model\n",
    "results, preds = model.predict(train, return_predictions=True ,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /data/dimitriosi_datasets/DeepMTP_v2/results/25_05_2022__10_27_12/model.pt...  \n",
      "Done\n",
      "Selected device: cuda:1\n",
      "Applying saved weights... Done\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220525_102836-14ekdw2r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/14ekdw2r\" target=\"_blank\">valiant-planet-62</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Done\n",
      "Epoch:2... Done\n",
      "  Validating... Done\n",
      "Epoch:3... Done\n",
      "  Validating... Done\n",
      "Epoch:4... Done\n",
      "  Validating... Done\n",
      "Epoch:5... Done\n",
      "  Validating... Done\n",
      "Epoch:6... Done\n",
      "  Validating... Done\n",
      "Epoch:7... Done\n",
      "  Validating... Done\n",
      "Epoch:8... Done\n",
      "  Validating... Done\n",
      "Epoch:9... Done\n",
      "  Validating... Done\n",
      "Epoch:10... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 9\n",
      "Epoch:11... Done\n",
      "  Validating... Done\n",
      "Epoch:12... Done\n",
      "  Validating... Done\n",
      "Epoch:13... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 12\n",
      "Epoch:14... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 12\n",
      "Epoch:15... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 3 out of 10---------------------- best epoch currently 12\n",
      "Epoch:16... Done\n",
      "  Validating... Done\n",
      "Epoch:17... Done\n",
      "  Validating... Done\n",
      "Epoch:18... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 17\n",
      "Epoch:19... Done\n",
      "  Validating... Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_auroc_macro</td><td>▁█</td></tr><tr><td>val_hamming_loss_macro</td><td>▁▁</td></tr><tr><td>val_loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.58472</td></tr><tr><td>test_hamming_loss_macro</td><td>0.23111</td></tr><tr><td>train_auroc_macro</td><td>0.58376</td></tr><tr><td>train_hamming_loss_macro</td><td>0.23232</td></tr><tr><td>train_loss</td><td>0.4838</td></tr><tr><td>val_auroc_macro</td><td>0.58085</td></tr><tr><td>val_hamming_loss_macro</td><td>0.22975</td></tr><tr><td>val_loss</td><td>0.49449</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">valiant-planet-62</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/14ekdw2r\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/14ekdw2r</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220525_102836-14ekdw2r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+-------------+\n",
      "|  mode | #epoch |  loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "| train |   0    | 0.6341 |       0.2567       |    0.5211   |\n",
      "| train |   1    | 0.5626 |         -          |      -      |\n",
      "| train |   2    | 0.522  |         -          |      -      |\n",
      "| train |   3    | 0.5055 |         -          |      -      |\n",
      "| train |   4    | 0.498  |         -          |      -      |\n",
      "| train |   5    | 0.4943 |         -          |      -      |\n",
      "| train |   6    | 0.4923 |         -          |      -      |\n",
      "| train |   7    | 0.4906 |         -          |      -      |\n",
      "| train |   8    |  0.49  |         -          |      -      |\n",
      "| train |   9    | 0.4892 |         -          |      -      |\n",
      "| train |   10   | 0.488  |       0.2323       |    0.5838   |\n",
      "| train |   11   | 0.4884 |         -          |      -      |\n",
      "| train |   12   | 0.4873 |         -          |      -      |\n",
      "| train |   13   | 0.4862 |         -          |      -      |\n",
      "| train |   14   | 0.4856 |         -          |      -      |\n",
      "| train |   15   | 0.4858 |         -          |      -      |\n",
      "| train |   16   | 0.4848 |         -          |      -      |\n",
      "| train |   17   | 0.4846 |         -          |      -      |\n",
      "| train |   18   | 0.4838 |         -          |      -      |\n",
      "| train |   19   | 0.4838 |         -          |      -      |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 0.5982 |       0.2297       |    0.5424   |      0/10      |\n",
      "| val  |   1    | 0.5323 |         -          |      -      |      0/10      |\n",
      "| val  |   2    | 0.5103 |         -          |      -      |      0/10      |\n",
      "| val  |   3    | 0.5018 |         -          |      -      |      0/10      |\n",
      "| val  |   4    | 0.4986 |         -          |      -      |      0/10      |\n",
      "| val  |   5    | 0.4972 |         -          |      -      |      0/10      |\n",
      "| val  |   6    | 0.4965 |         -          |      -      |      0/10      |\n",
      "| val  |   7    | 0.4961 |         -          |      -      |      0/10      |\n",
      "| val  |   8    | 0.4961 |         -          |      -      |      0/10      |\n",
      "| val  |   9    | 0.4957 |         -          |      -      |      0/10      |\n",
      "| val  |   10   | 0.4957 |       0.2297       |    0.5809   |      1/10      |\n",
      "| val  |   11   | 0.4953 |         -          |      -      |      0/10      |\n",
      "| val  |   12   | 0.4951 |         -          |      -      |      0/10      |\n",
      "| val  |   13   | 0.4952 |         -          |      -      |      1/10      |\n",
      "| val  |   14   | 0.4953 |         -          |      -      |      2/10      |\n",
      "| val  |   15   | 0.4952 |         -          |      -      |      3/10      |\n",
      "| val  |   16   | 0.495  |         -          |      -      |      0/10      |\n",
      "| val  |   17   | 0.495  |         -          |      -      |      0/10      |\n",
      "| val  |   18   | 0.4951 |         -          |      -      |      1/10      |\n",
      "| val  |   19   | 0.4945 |         -          |      -      |      0/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   19   |  -   |       0.2311       |    0.5847   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n"
     ]
    }
   ],
   "source": [
    "# this is a minimal configuration needed for HPO methods like Hyperband\n",
    "config = {\n",
    "    'verbose': True,\n",
    "    'num_epochs': 20,\n",
    "    'num_workers': 8,\n",
    "    # 'wandb_project_name': None,\n",
    "    # 'wandb_project_entity': None,\n",
    "    # 'use_tensorboard_logger': False\n",
    "}\n",
    "# initialize the model and load the pretrained weights etc.\n",
    "new_model = DeepMTP(config, 'add path to model.pt')\n",
    "\n",
    "new_model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deepMTP_env_source': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0bffa426c47be87a03a22c79420a878934c6514bf0edb62313e132440f2a8f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
