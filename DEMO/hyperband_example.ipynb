{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimitriosi/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.chdir('../')\n",
    "\n",
    "from ast import arg\n",
    "from DeepMTP.simple_hyperband import BaseWorker\n",
    "from DeepMTP.simple_hyperband import HyperBand\n",
    "from DeepMTP.dataset import load_process_MLC, load_process_MTR, load_process_DP, process_dummy_MLC, process_dummy_MTR, process_dummy_DP, load_process_MC\n",
    "from DeepMTP.utils.data_utils_v2 import data_process, BaseDataset\n",
    "from DeepMTP.utils.utils import generate_config\n",
    "\n",
    "import ConfigSpace.hyperparameters as CSH\n",
    "import ConfigSpace as CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(batch_norm | instance_branch_layers > 1 || batch_norm | target_branch_layers > 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the configuration space\n",
    "cs= CS.ConfigurationSpace()\n",
    "\n",
    "lr= CSH.UniformFloatHyperparameter(\n",
    "    \"learning_rate\", lower=1e-6, upper=1e-3, default_value=\"1e-3\", log=True\n",
    ")\n",
    "cs.add_hyperparameters([lr])\n",
    "\n",
    "embedding_size= CSH.UniformIntegerHyperparameter(\n",
    "    \"embedding_size\", lower=8, upper=2048, default_value=64, log=False\n",
    ")\n",
    "\n",
    "instance_branch_layers= CSH.UniformIntegerHyperparameter(\n",
    "    \"instance_branch_layers\", lower=1, upper=2, default_value=1, log=False\n",
    ")\n",
    "\n",
    "instance_branch_nodes_per_layer= CSH.UniformIntegerHyperparameter(\n",
    "    \"instance_branch_nodes_per_layer\", lower=8, upper=2048, default_value=64, log=False\n",
    ")\n",
    "\n",
    "target_branch_layers = CSH.UniformIntegerHyperparameter(\n",
    "    \"target_branch_layers\", lower=1, upper=2, default_value=1, log=False\n",
    ")\n",
    "\n",
    "target_branch_nodes_per_layer = CSH.UniformIntegerHyperparameter(\n",
    "    \"target_branch_nodes_per_layer\", lower=8, upper=2048, default_value=64, log=False\n",
    ")\n",
    "\n",
    "dropout_rate = CSH.UniformFloatHyperparameter(\n",
    "    \"dropout_rate\", lower=0.0, upper=0.9, default_value=0.4, log=False\n",
    ")\n",
    "\n",
    "batch_norm = CSH.CategoricalHyperparameter(\"batch_norm\", [\"yes\", \"no\"])\n",
    "\n",
    "cs.add_hyperparameters(\n",
    "    [\n",
    "        embedding_size,\n",
    "        instance_branch_layers,\n",
    "        instance_branch_nodes_per_layer,\n",
    "        target_branch_layers,\n",
    "        target_branch_nodes_per_layer,\n",
    "        dropout_rate,\n",
    "        batch_norm,\n",
    "    ]\n",
    ")\n",
    "\n",
    "cond = CS.GreaterThanCondition(dropout_rate, instance_branch_layers, 1)\n",
    "# cs.add_condition(cond)\n",
    "\n",
    "cond2 = CS.GreaterThanCondition(batch_norm, instance_branch_layers, 1)\n",
    "# cs.add_condition(cond2)\n",
    "\n",
    "cond3 = CS.GreaterThanCondition(dropout_rate, target_branch_layers, 1)\n",
    "# cs.add_condition(cond)\n",
    "\n",
    "cond4 = CS.GreaterThanCondition(batch_norm, target_branch_layers, 1)\n",
    "# cs.add_condition(cond2)\n",
    "\n",
    "cs.add_condition(CS.OrConjunction(cond, cond3))\n",
    "cs.add_condition(CS.OrConjunction(cond2, cond4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "yeast:undivided - exists, not redownloading\n",
      "Done\n",
      "Interaction file: 2d numpy array format detected\n",
      "Interaction file: checking format consistency... Passed\n",
      "Interaction file: checking instance id format consistency... Passed\n",
      "Interaction file: checking target id type consistency... Passed\n",
      "\n",
      "Interaction file: checking target variable type consistency... Passed\n",
      "Automatically detected type of target variable type: binary\n",
      "\n",
      "-- Test set was not provided, could not detect if novel instances exist or not \n",
      "-- Test set was not provided, could not detect if novel targets exist or not \n",
      "\n",
      "Instance features file: processing features... Done\n",
      "\n",
      "Cross input consistency for (numpy) interaction data and instance features checks out\n",
      "-- Same instance ids in the interaction and features files for the train set\n",
      "\n",
      "Splitting train to train-test according to validation setting B... Done\n",
      "Splitting train to train-val according to validation setting B... Done\n"
     ]
    }
   ],
   "source": [
    "data = load_process_MLC(dataset_name='yeast', variant='undivided')\n",
    "train, val, test, data_info = data_process(data, validation_setting='B', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detected_validation_setting': 'B',\n",
       " 'detected_problem_mode': 'classification',\n",
       " 'instance_branch_input_dim': 103,\n",
       " 'target_branch_input_dim': 14}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {    \n",
    "\n",
    "    'hpo_results_path': './hyperband/',\n",
    "\n",
    "    'instance_branch_input_dim': data_info['instance_branch_input_dim'],\n",
    "    'target_branch_input_dim': data_info['target_branch_input_dim'],\n",
    "    'validation_setting': data_info['detected_validation_setting'],\n",
    "    'enable_dot_product_version': True,\n",
    "    'problem_mode': data_info['detected_problem_mode'],\n",
    "\n",
    "    'compute_mode': 'cuda:1',\n",
    "    'train_batchsize': 512,\n",
    "    'val_batchsize': 512,\n",
    "    'num_epochs': 6,\n",
    "    'num_workers': 8,\n",
    "\n",
    "    'metrics': ['hamming_loss', 'auroc'],\n",
    "    'metrics_average': ['macro'],\n",
    "    'patience': 10,\n",
    "\n",
    "    'evaluate_train': True,\n",
    "    'evaluate_val': True,\n",
    "\n",
    "    'verbose': True,\n",
    "    'results_verbose': False,\n",
    "    'use_early_stopping': True,\n",
    "    'use_tensorboard_logger': True,\n",
    "    'wandb_project_name': 'DeepMTP_v2',\n",
    "    'wandb_project_entity': 'diliadis',\n",
    "    'metric_to_optimize_early_stopping': 'loss',\n",
    "    'metric_to_optimize_best_epoch_selection': 'loss',\n",
    "\n",
    "    'instance_branch_architecture': 'MLP',\n",
    "\n",
    "    'target_branch_architecture': 'MLP',\n",
    "\n",
    "    'save_model': True,\n",
    "\n",
    "    'eval_every_n_epochs': 10,\n",
    "\n",
    "    'additional_info': {'eta': 3, 'max_budget': 9}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker = BaseWorker(\n",
    "    train, val, test, data_info, config, 'loss'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hpo_results_path': './hyperband/',\n",
       " 'instance_branch_input_dim': 103,\n",
       " 'target_branch_input_dim': 14,\n",
       " 'validation_setting': 'B',\n",
       " 'enable_dot_product_version': True,\n",
       " 'problem_mode': 'classification',\n",
       " 'compute_mode': 'cuda:1',\n",
       " 'train_batchsize': 512,\n",
       " 'val_batchsize': 512,\n",
       " 'num_epochs': 6,\n",
       " 'num_workers': 8,\n",
       " 'metrics': ['hamming_loss', 'auroc'],\n",
       " 'metrics_average': ['macro'],\n",
       " 'patience': 10,\n",
       " 'evaluate_train': True,\n",
       " 'evaluate_val': True,\n",
       " 'verbose': True,\n",
       " 'results_verbose': False,\n",
       " 'use_early_stopping': True,\n",
       " 'use_tensorboard_logger': True,\n",
       " 'wandb_project_name': 'DeepMTP_v2',\n",
       " 'wandb_project_entity': 'diliadis',\n",
       " 'metric_to_optimize_early_stopping': 'loss',\n",
       " 'metric_to_optimize_best_epoch_selection': 'loss',\n",
       " 'instance_branch_architecture': 'MLP',\n",
       " 'target_branch_architecture': 'MLP',\n",
       " 'save_model': True,\n",
       " 'eval_every_n_epochs': 10,\n",
       " 'additional_info': {'eta': 3, 'max_budget': 9}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker.base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb = HyperBand(\n",
    "    base_worker=worker,\n",
    "    configspace=cs,\n",
    "    eta=config['additional_info']['eta'],\n",
    "    max_budget=config['additional_info']['max_budget'],\n",
    "    direction=\"min\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdiliadis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220528_184918-7dkqgqbr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/7dkqgqbr\" target=\"_blank\">rosy-bee-74</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁</td></tr><tr><td>train_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_auroc_macro</td><td>▁</td></tr><tr><td>val_hamming_loss_macro</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.5084</td></tr><tr><td>test_hamming_loss_macro</td><td>0.69599</td></tr><tr><td>train_auroc_macro</td><td>0.50153</td></tr><tr><td>train_hamming_loss_macro</td><td>0.69716</td></tr><tr><td>train_loss</td><td>69.72705</td></tr><tr><td>val_auroc_macro</td><td>0.49281</td></tr><tr><td>val_hamming_loss_macro</td><td>0.7025</td></tr><tr><td>val_loss</td><td>10.11122</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rosy-bee-74</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/7dkqgqbr\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/7dkqgqbr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220528_184918-7dkqgqbr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+--------------------+-------------+\n",
      "|  mode | #epoch |   loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "| train |   0    | 69.7271 |       0.6972       |    0.5015   |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |   loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 10.1112 |       0.7025       |    0.4928   |      0/10      |\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   0    |  -   |       0.696        |    0.5084   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220528_184948-21bkl9pi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/21bkl9pi\" target=\"_blank\">volcanic-shadow-75</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁</td></tr><tr><td>train_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_auroc_macro</td><td>▁</td></tr><tr><td>val_hamming_loss_macro</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.4967</td></tr><tr><td>test_hamming_loss_macro</td><td>0.69599</td></tr><tr><td>train_auroc_macro</td><td>0.48777</td></tr><tr><td>train_hamming_loss_macro</td><td>0.30284</td></tr><tr><td>train_loss</td><td>0.71481</td></tr><tr><td>val_auroc_macro</td><td>0.50565</td></tr><tr><td>val_hamming_loss_macro</td><td>0.7025</td></tr><tr><td>val_loss</td><td>0.70955</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">volcanic-shadow-75</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/21bkl9pi\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/21bkl9pi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220528_184948-21bkl9pi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+-------------+\n",
      "|  mode | #epoch |  loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "| train |   0    | 0.7148 |       0.3028       |    0.4878   |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 0.7096 |       0.7025       |    0.5057   |      0/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   0    |  -   |       0.696        |    0.4967   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220528_185008-1nuwx72j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/1nuwx72j\" target=\"_blank\">cerulean-serenity-76</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁</td></tr><tr><td>train_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_auroc_macro</td><td>▁</td></tr><tr><td>val_hamming_loss_macro</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.56058</td></tr><tr><td>test_hamming_loss_macro</td><td>0.23111</td></tr><tr><td>train_auroc_macro</td><td>0.50627</td></tr><tr><td>train_hamming_loss_macro</td><td>0.28124</td></tr><tr><td>train_loss</td><td>0.63036</td></tr><tr><td>val_auroc_macro</td><td>0.54247</td></tr><tr><td>val_hamming_loss_macro</td><td>0.22975</td></tr><tr><td>val_loss</td><td>0.52637</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cerulean-serenity-76</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/1nuwx72j\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/1nuwx72j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220528_185008-1nuwx72j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+-------------+\n",
      "|  mode | #epoch |  loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "| train |   0    | 0.6304 |       0.2812       |    0.5063   |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 0.5264 |       0.2297       |    0.5425   |      0/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   0    |  -   |       0.2311       |    0.5606   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220528_185033-392x0ebs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/392x0ebs\" target=\"_blank\">avid-snow-77</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁</td></tr><tr><td>train_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_auroc_macro</td><td>▁</td></tr><tr><td>val_hamming_loss_macro</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.55017</td></tr><tr><td>test_hamming_loss_macro</td><td>0.23111</td></tr><tr><td>train_auroc_macro</td><td>0.50874</td></tr><tr><td>train_hamming_loss_macro</td><td>0.30243</td></tr><tr><td>train_loss</td><td>0.66393</td></tr><tr><td>val_auroc_macro</td><td>0.54956</td></tr><tr><td>val_hamming_loss_macro</td><td>0.22975</td></tr><tr><td>val_loss</td><td>0.56819</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">avid-snow-77</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/392x0ebs\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/392x0ebs</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220528_185033-392x0ebs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+-------------+\n",
      "|  mode | #epoch |  loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "| train |   0    | 0.6639 |       0.3024       |    0.5087   |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 0.5682 |       0.2297       |    0.5496   |      0/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   0    |  -   |       0.2311       |    0.5502   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220528_185055-9a0p4r0b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/9a0p4r0b\" target=\"_blank\">whole-feather-78</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁</td></tr><tr><td>train_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_auroc_macro</td><td>▁</td></tr><tr><td>val_hamming_loss_macro</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.53246</td></tr><tr><td>test_hamming_loss_macro</td><td>0.23332</td></tr><tr><td>train_auroc_macro</td><td>0.50263</td></tr><tr><td>train_hamming_loss_macro</td><td>0.30284</td></tr><tr><td>train_loss</td><td>0.70081</td></tr><tr><td>val_auroc_macro</td><td>0.53448</td></tr><tr><td>val_hamming_loss_macro</td><td>0.23012</td></tr><tr><td>val_loss</td><td>0.68814</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">whole-feather-78</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/9a0p4r0b\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/9a0p4r0b</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220528_185055-9a0p4r0b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+-------------+\n",
      "|  mode | #epoch |  loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "| train |   0    | 0.7008 |       0.3028       |    0.5026   |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 0.6881 |       0.2301       |    0.5345   |      0/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   0    |  -   |       0.2333       |    0.5325   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220528_185116-1idohm1e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/1idohm1e\" target=\"_blank\">glorious-cloud-79</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁</td></tr><tr><td>train_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_auroc_macro</td><td>▁</td></tr><tr><td>val_hamming_loss_macro</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.48407</td></tr><tr><td>test_hamming_loss_macro</td><td>0.69599</td></tr><tr><td>train_auroc_macro</td><td>0.50146</td></tr><tr><td>train_hamming_loss_macro</td><td>0.69703</td></tr><tr><td>train_loss</td><td>0.89946</td></tr><tr><td>val_auroc_macro</td><td>0.53491</td></tr><tr><td>val_hamming_loss_macro</td><td>0.7025</td></tr><tr><td>val_loss</td><td>0.87362</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">glorious-cloud-79</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/1idohm1e\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/1idohm1e</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220528_185116-1idohm1e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+-------------+\n",
      "|  mode | #epoch |  loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "| train |   0    | 0.8995 |       0.697        |    0.5015   |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 0.8736 |       0.7025       |    0.5349   |      0/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   0    |  -   |       0.696        |    0.4841   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220528_185140-37sx6gs7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/37sx6gs7\" target=\"_blank\">logical-cosmos-80</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁</td></tr><tr><td>train_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_auroc_macro</td><td>▁</td></tr><tr><td>val_hamming_loss_macro</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.49497</td></tr><tr><td>test_hamming_loss_macro</td><td>0.61452</td></tr><tr><td>train_auroc_macro</td><td>0.50705</td></tr><tr><td>train_hamming_loss_macro</td><td>0.30284</td></tr><tr><td>train_loss</td><td>0.69634</td></tr><tr><td>val_auroc_macro</td><td>0.55214</td></tr><tr><td>val_hamming_loss_macro</td><td>0.61524</td></tr><tr><td>val_loss</td><td>0.69362</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">logical-cosmos-80</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/37sx6gs7\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/37sx6gs7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220528_185140-37sx6gs7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+-------------+\n",
      "|  mode | #epoch |  loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "| train |   0    | 0.6963 |       0.3028       |    0.5071   |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 0.6936 |       0.6152       |    0.5521   |      0/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   0    |  -   |       0.6145       |    0.495    |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220528_185203-1v8pt1v0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/1v8pt1v0\" target=\"_blank\">absurd-donkey-81</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁</td></tr><tr><td>train_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_auroc_macro</td><td>▁</td></tr><tr><td>val_hamming_loss_macro</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.50077</td></tr><tr><td>test_hamming_loss_macro</td><td>0.69599</td></tr><tr><td>train_auroc_macro</td><td>0.50213</td></tr><tr><td>train_hamming_loss_macro</td><td>0.69716</td></tr><tr><td>train_loss</td><td>69.72373</td></tr><tr><td>val_auroc_macro</td><td>0.49707</td></tr><tr><td>val_hamming_loss_macro</td><td>0.7025</td></tr><tr><td>val_loss</td><td>70.12441</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">absurd-donkey-81</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/1v8pt1v0\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/1v8pt1v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220528_185203-1v8pt1v0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+--------------------+-------------+\n",
      "|  mode | #epoch |   loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "| train |   0    | 69.7237 |       0.6972       |    0.5021   |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |   loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 70.1244 |       0.7025       |    0.4971   |      0/10      |\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   0    |  -   |       0.696        |    0.5008   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220528_185228-aiysljvm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/aiysljvm\" target=\"_blank\">prime-sound-82</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁</td></tr><tr><td>train_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_auroc_macro</td><td>▁</td></tr><tr><td>val_hamming_loss_macro</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.5</td></tr><tr><td>test_hamming_loss_macro</td><td>0.69599</td></tr><tr><td>train_auroc_macro</td><td>0.4926</td></tr><tr><td>train_hamming_loss_macro</td><td>0.69716</td></tr><tr><td>train_loss</td><td>69.70382</td></tr><tr><td>val_auroc_macro</td><td>0.5</td></tr><tr><td>val_hamming_loss_macro</td><td>0.7025</td></tr><tr><td>val_loss</td><td>70.2065</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">prime-sound-82</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/aiysljvm\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/aiysljvm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220528_185228-aiysljvm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+--------------------+-------------+\n",
      "|  mode | #epoch |   loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "| train |   0    | 69.7038 |       0.6972       |    0.4926   |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |   loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 70.2065 |       0.7025       |     0.5     |      0/10      |\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   0    |  -   |       0.696        |     0.5     |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "Loading checkpoint from ./hyperband/28_05_2022__18_49_05//28_05_2022__18_49_06/model.pt...  \n",
      "Done\n",
      "Selected device: cuda:1\n",
      "Applying saved weights... Done\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220528_185251-341fhslj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/341fhslj\" target=\"_blank\">cool-eon-83</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 0\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>▁▁</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>val_auroc_macro</td><td>▁▁</td></tr><tr><td>val_hamming_loss_macro</td><td>▁▁</td></tr><tr><td>val_loss</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.50008</td></tr><tr><td>test_hamming_loss_macro</td><td>0.69599</td></tr><tr><td>train_auroc_macro</td><td>0.50244</td></tr><tr><td>train_hamming_loss_macro</td><td>0.69716</td></tr><tr><td>train_loss</td><td>69.70369</td></tr><tr><td>val_auroc_macro</td><td>0.5</td></tr><tr><td>val_hamming_loss_macro</td><td>0.7025</td></tr><tr><td>val_loss</td><td>70.2065</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cool-eon-83</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/341fhslj\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/341fhslj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220528_185251-341fhslj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+--------------------+-------------+\n",
      "|  mode | #epoch |   loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "| train |   0    | 69.7071 |       0.6972       |    0.4858   |\n",
      "| train |   1    | 69.7037 |       0.6972       |    0.5024   |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |   loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 70.2065 |       0.7025       |     0.5     |      0/10      |\n",
      "| val  |   1    | 70.2065 |       0.7025       |     0.5     |      1/10      |\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   0    |  -   |       0.696        |    0.5001   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "Loading checkpoint from ./hyperband/28_05_2022__18_49_05//28_05_2022__18_49_48/model.pt...  \n",
      "Done\n",
      "Selected device: cuda:1\n",
      "Applying saved weights... Done\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220528_185323-tqs1zisc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/tqs1zisc\" target=\"_blank\">fluent-thunder-84</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>▁▁</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>val_auroc_macro</td><td>▁█</td></tr><tr><td>val_hamming_loss_macro</td><td>▁▁</td></tr><tr><td>val_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.49698</td></tr><tr><td>test_hamming_loss_macro</td><td>0.69599</td></tr><tr><td>train_auroc_macro</td><td>0.50235</td></tr><tr><td>train_hamming_loss_macro</td><td>0.30284</td></tr><tr><td>train_loss</td><td>0.7004</td></tr><tr><td>val_auroc_macro</td><td>0.52108</td></tr><tr><td>val_hamming_loss_macro</td><td>0.7025</td></tr><tr><td>val_loss</td><td>0.6985</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fluent-thunder-84</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/tqs1zisc\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/tqs1zisc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220528_185323-tqs1zisc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+-------------+\n",
      "|  mode | #epoch |  loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "| train |   0    | 0.7058 |       0.3028       |    0.5005   |\n",
      "| train |   1    | 0.7004 |       0.3028       |    0.5023   |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 0.7028 |       0.7025       |    0.5138   |      0/10      |\n",
      "| val  |   1    | 0.6985 |       0.7025       |    0.5211   |      0/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   1    |  -   |       0.696        |    0.497    |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "Loading checkpoint from ./hyperband/28_05_2022__18_49_05//28_05_2022__18_50_08/model.pt...  \n",
      "Done\n",
      "Selected device: cuda:1\n",
      "Applying saved weights... Done\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220528_185352-388lhycg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/388lhycg\" target=\"_blank\">iconic-river-85</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>val_auroc_macro</td><td>▁█</td></tr><tr><td>val_hamming_loss_macro</td><td>█▁</td></tr><tr><td>val_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.63621</td></tr><tr><td>test_hamming_loss_macro</td><td>0.22152</td></tr><tr><td>train_auroc_macro</td><td>0.63417</td></tr><tr><td>train_hamming_loss_macro</td><td>0.22989</td></tr><tr><td>train_loss</td><td>0.47745</td></tr><tr><td>val_auroc_macro</td><td>0.63339</td></tr><tr><td>val_hamming_loss_macro</td><td>0.21834</td></tr><tr><td>val_loss</td><td>0.47551</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">iconic-river-85</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/388lhycg\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/388lhycg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220528_185352-388lhycg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+-------------+\n",
      "|  mode | #epoch |  loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "| train |   0    | 0.5013 |       0.2326       |    0.5537   |\n",
      "| train |   1    | 0.4774 |       0.2299       |    0.6342   |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 0.4913 |       0.2297       |    0.6121   |      0/10      |\n",
      "| val  |   1    | 0.4755 |       0.2183       |    0.6334   |      0/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   1    |  -   |       0.2215       |    0.6362   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "Loading checkpoint from ./hyperband/28_05_2022__18_49_05//28_05_2022__18_52_50/model.pt...  \n",
      "Done\n",
      "Selected device: cuda:1\n",
      "Applying saved weights... Done\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220528_185421-27jmw16w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/27jmw16w\" target=\"_blank\">winter-mountain-86</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 0\n",
      "Epoch:2... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 0\n",
      "Epoch:3... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 3 out of 10---------------------- best epoch currently 0\n",
      "Epoch:4... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 4 out of 10---------------------- best epoch currently 0\n",
      "Epoch:5... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "-----------------------------EarlyStopping counter: 5 out of 10---------------------- best epoch currently 0\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>█▁</td></tr><tr><td>train_hamming_loss_macro</td><td>▁▁</td></tr><tr><td>train_loss</td><td>▄▁▇█▁▁</td></tr><tr><td>val_auroc_macro</td><td>▁▁</td></tr><tr><td>val_hamming_loss_macro</td><td>▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.5</td></tr><tr><td>test_hamming_loss_macro</td><td>0.69599</td></tr><tr><td>train_auroc_macro</td><td>0.5032</td></tr><tr><td>train_hamming_loss_macro</td><td>0.69716</td></tr><tr><td>train_loss</td><td>69.69317</td></tr><tr><td>val_auroc_macro</td><td>0.5</td></tr><tr><td>val_hamming_loss_macro</td><td>0.7025</td></tr><tr><td>val_loss</td><td>70.2065</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">winter-mountain-86</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/27jmw16w\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/27jmw16w</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220528_185421-27jmw16w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+--------------------+-------------+\n",
      "|  mode | #epoch |   loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "| train |   0    | 69.7204 |       0.6972       |    0.5075   |\n",
      "| train |   1    | 69.6938 |         -          |      -      |\n",
      "| train |   2    | 69.7433 |         -          |      -      |\n",
      "| train |   3    | 69.7497 |         -          |      -      |\n",
      "| train |   4    | 69.6965 |         -          |      -      |\n",
      "| train |   5    | 69.6932 |       0.6972       |    0.5032   |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |   loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 70.2065 |       0.7025       |     0.5     |      0/10      |\n",
      "| val  |   1    | 70.2065 |         -          |      -      |      1/10      |\n",
      "| val  |   2    | 70.2065 |         -          |      -      |      2/10      |\n",
      "| val  |   3    | 70.2065 |         -          |      -      |      3/10      |\n",
      "| val  |   4    | 70.2065 |         -          |      -      |      4/10      |\n",
      "| val  |   5    | 70.2065 |       0.7025       |     0.5     |      5/10      |\n",
      "+------+--------+---------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   0    |  -   |       0.696        |     0.5     |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220528_185515-3h749kti</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/3h749kti\" target=\"_blank\">sage-field-87</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Done\n",
      "Epoch:2... Done\n",
      "  Validating... Done\n",
      "Epoch:3... Done\n",
      "  Validating... Done\n",
      "Epoch:4... Done\n",
      "  Validating... Done\n",
      "Epoch:5... Done\n",
      "  Validating... Done\n",
      "Epoch:6... Done\n",
      "  Validating... Done\n",
      "Epoch:7... Done\n",
      "  Validating... Done\n",
      "Epoch:8... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▅▃▂▂▂▁▁▁</td></tr><tr><td>val_auroc_macro</td><td>▁█</td></tr><tr><td>val_hamming_loss_macro</td><td>█▁</td></tr><tr><td>val_loss</td><td>█▅▄▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.52966</td></tr><tr><td>test_hamming_loss_macro</td><td>0.2317</td></tr><tr><td>train_auroc_macro</td><td>0.53645</td></tr><tr><td>train_hamming_loss_macro</td><td>0.30284</td></tr><tr><td>train_loss</td><td>0.67916</td></tr><tr><td>val_auroc_macro</td><td>0.5433</td></tr><tr><td>val_hamming_loss_macro</td><td>0.22938</td></tr><tr><td>val_loss</td><td>0.67729</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sage-field-87</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/3h749kti\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/3h749kti</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220528_185515-3h749kti/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+-------------+\n",
      "|  mode | #epoch |  loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "| train |   0    | 0.8813 |       0.6718       |    0.5121   |\n",
      "| train |   1    | 0.7899 |         -          |      -      |\n",
      "| train |   2    | 0.7454 |         -          |      -      |\n",
      "| train |   3    | 0.7205 |         -          |      -      |\n",
      "| train |   4    | 0.7055 |         -          |      -      |\n",
      "| train |   5    | 0.6956 |         -          |      -      |\n",
      "| train |   6    | 0.6886 |         -          |      -      |\n",
      "| train |   7    | 0.6834 |         -          |      -      |\n",
      "| train |   8    | 0.6792 |       0.3028       |    0.5364   |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 0.8257 |       0.7025       |    0.4992   |      0/10      |\n",
      "| val  |   1    | 0.7636 |         -          |      -      |      0/10      |\n",
      "| val  |   2    | 0.7312 |         -          |      -      |      0/10      |\n",
      "| val  |   3    | 0.7121 |         -          |      -      |      0/10      |\n",
      "| val  |   4    | 0.7001 |         -          |      -      |      0/10      |\n",
      "| val  |   5    | 0.6919 |         -          |      -      |      0/10      |\n",
      "| val  |   6    | 0.6859 |         -          |      -      |      0/10      |\n",
      "| val  |   7    | 0.6812 |         -          |      -      |      0/10      |\n",
      "| val  |   8    | 0.6773 |       0.2294       |    0.5433   |      0/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   8    |  -   |       0.2317       |    0.5297   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220528_185623-1b17ymw5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/1b17ymw5\" target=\"_blank\">flowing-gorge-88</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Done\n",
      "Epoch:2... Done\n",
      "  Validating... Done\n",
      "Epoch:3... Done\n",
      "  Validating... Done\n",
      "Epoch:4... Done\n",
      "  Validating... Done\n",
      "Epoch:5... Done\n",
      "  Validating... Done\n",
      "Epoch:6... Done\n",
      "  Validating... Done\n",
      "Epoch:7... Done\n",
      "  Validating... Done\n",
      "Epoch:8... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁</td></tr><tr><td>val_auroc_macro</td><td>▁█</td></tr><tr><td>val_hamming_loss_macro</td><td>█▁</td></tr><tr><td>val_loss</td><td>█▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.61805</td></tr><tr><td>test_hamming_loss_macro</td><td>0.21281</td></tr><tr><td>train_auroc_macro</td><td>0.64144</td></tr><tr><td>train_hamming_loss_macro</td><td>0.21153</td></tr><tr><td>train_loss</td><td>0.45584</td></tr><tr><td>val_auroc_macro</td><td>0.61272</td></tr><tr><td>val_hamming_loss_macro</td><td>0.20619</td></tr><tr><td>val_loss</td><td>0.47233</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">flowing-gorge-88</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/1b17ymw5\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/1b17ymw5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220528_185623-1b17ymw5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+-------------+\n",
      "|  mode | #epoch |  loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "| train |   0    | 69.485 |       0.6972       |    0.4988   |\n",
      "| train |   1    | 1.0829 |         -          |      -      |\n",
      "| train |   2    | 0.5451 |         -          |      -      |\n",
      "| train |   3    | 0.5007 |         -          |      -      |\n",
      "| train |   4    | 0.4844 |         -          |      -      |\n",
      "| train |   5    | 0.4757 |         -          |      -      |\n",
      "| train |   6    | 0.4681 |         -          |      -      |\n",
      "| train |   7    | 0.4616 |         -          |      -      |\n",
      "| train |   8    | 0.4558 |       0.2115       |    0.6414   |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 4.589  |       0.7025       |    0.506    |      0/10      |\n",
      "| val  |   1    | 0.5843 |         -          |      -      |      0/10      |\n",
      "| val  |   2    | 0.5172 |         -          |      -      |      0/10      |\n",
      "| val  |   3    | 0.4937 |         -          |      -      |      0/10      |\n",
      "| val  |   4    | 0.4862 |         -          |      -      |      0/10      |\n",
      "| val  |   5    | 0.4813 |         -          |      -      |      0/10      |\n",
      "| val  |   6    | 0.4773 |         -          |      -      |      0/10      |\n",
      "| val  |   7    | 0.4753 |         -          |      -      |      0/10      |\n",
      "| val  |   8    | 0.4723 |       0.2062       |    0.6127   |      0/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   8    |  -   |       0.2128       |    0.6181   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n",
      "Selected device: cuda:1\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220528_185740-1i8x4l0u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/1i8x4l0u\" target=\"_blank\">polar-sunset-89</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Done\n",
      "Epoch:2... Done\n",
      "  Validating... Done\n",
      "Epoch:3... Done\n",
      "  Validating... Done\n",
      "Epoch:4... Done\n",
      "  Validating... Done\n",
      "Epoch:5... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 4\n",
      "Epoch:6... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 4\n",
      "Epoch:7... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 3 out of 10---------------------- best epoch currently 4\n",
      "Epoch:8... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "-----------------------------EarlyStopping counter: 4 out of 10---------------------- best epoch currently 4\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁</td></tr><tr><td>val_auroc_macro</td><td>▁█</td></tr><tr><td>val_hamming_loss_macro</td><td>█▁</td></tr><tr><td>val_loss</td><td>█▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.64255</td></tr><tr><td>test_hamming_loss_macro</td><td>0.20573</td></tr><tr><td>train_auroc_macro</td><td>0.80108</td></tr><tr><td>train_hamming_loss_macro</td><td>0.14257</td></tr><tr><td>train_loss</td><td>0.34207</td></tr><tr><td>val_auroc_macro</td><td>0.68174</td></tr><tr><td>val_hamming_loss_macro</td><td>0.20545</td></tr><tr><td>val_loss</td><td>0.57419</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">polar-sunset-89</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/1i8x4l0u\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/1i8x4l0u</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220528_185740-1i8x4l0u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+--------------------+-------------+\n",
      "|  mode | #epoch |   loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "| train |   0    | 20.8283 |       0.4194       |    0.5005   |\n",
      "| train |   1    |  1.914  |         -          |      -      |\n",
      "| train |   2    |  0.5461 |         -          |      -      |\n",
      "| train |   3    |  0.5012 |         -          |      -      |\n",
      "| train |   4    |  0.4607 |         -          |      -      |\n",
      "| train |   5    |  0.419  |         -          |      -      |\n",
      "| train |   6    |  0.3876 |         -          |      -      |\n",
      "| train |   7    |  0.3623 |         -          |      -      |\n",
      "| train |   8    |  0.3421 |       0.1426       |    0.8011   |\n",
      "+-------+--------+---------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 7.1956 |       0.4912       |    0.4674   |      0/10      |\n",
      "| val  |   1    | 0.5817 |         -          |      -      |      0/10      |\n",
      "| val  |   2    | 0.5528 |         -          |      -      |      0/10      |\n",
      "| val  |   3    | 0.5347 |         -          |      -      |      0/10      |\n",
      "| val  |   4    | 0.486  |         -          |      -      |      0/10      |\n",
      "| val  |   5    | 0.4988 |         -          |      -      |      1/10      |\n",
      "| val  |   6    | 0.4977 |         -          |      -      |      2/10      |\n",
      "| val  |   7    | 0.5417 |         -          |      -      |      3/10      |\n",
      "| val  |   8    | 0.5742 |       0.2054       |    0.6817   |      4/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   4    |  -   |       0.2057       |    0.6425   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n"
     ]
    }
   ],
   "source": [
    "hb.run_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "676c3aacf589c44f0fd18842c3d1580abcf32f718a418064e53325ddf7611bf3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('deepMTP_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
