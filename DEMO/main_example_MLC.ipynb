{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.chdir('../')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from DeepMTP.dataset import load_process_MLC, load_process_MTR, load_process_DP, process_dummy_MLC, process_dummy_MTR, process_dummy_DP, load_process_MC, load_process_MTL\n",
    "from DeepMTP.utils.data_utils_v3 import data_process, BaseDataset\n",
    "from DeepMTP.tests import check_mlc_results, check_mtr_results, check_dp_results, check_mtl_results\n",
    "from DeepMTP.main import DeepMTP\n",
    "from DeepMTP.utils.utils import generate_config\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel classification\n",
    "<img src=\"../images/mlc_example.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load-process-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "yeast:undivided - exists, not redownloading\n",
      "Done\n",
      "Interaction file: 2d numpy array format detected\n",
      "Interaction file: checking format consistency... Passed\n",
      "Interaction file: checking instance id format consistency... Passed\n",
      "Interaction file: checking target id type consistency... Passed\n",
      "\n",
      "Interaction file: checking target variable type consistency... Passed\n",
      "Automatically detected type of target variable type: binary\n",
      "\n",
      "-- Test set was not provided, could not detect if novel instances exist or not \n",
      "-- Test set was not provided, could not detect if novel targets exist or not \n",
      "\n",
      "Instance features file: processing features... Done\n",
      "\n",
      "Cross input consistency for (numpy) interaction data and instance features checks out\n",
      "-- Same instance ids in the interaction and features files for the train set\n",
      "\n",
      "Splitting train to train-test according to validation setting B... Done\n",
      "Splitting train to train-val according to validation setting B... Done\n",
      "Checking if MLC splitting results are valid... Done\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "data = load_process_MLC(dataset_name='yeast', variant='undivided', features_type='numpy')\n",
    "# process and split\n",
    "train, val, test, data_info = data_process(data, validation_setting='B', verbose=True)\n",
    "# sanity check\n",
    "check_mlc_results(train, val, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure and train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = generate_config(    \n",
    "    instance_branch_input_dim = data_info['instance_branch_input_dim'],\n",
    "    target_branch_input_dim = data_info['target_branch_input_dim'],\n",
    "    validation_setting = data_info['detected_validation_setting'],\n",
    "    enable_dot_product_version = True,\n",
    "    problem_mode = data_info['detected_problem_mode'],\n",
    "    learning_rate = 0.001,\n",
    "    decay = 0,\n",
    "    batch_norm = False,\n",
    "    dropout_rate = 0,\n",
    "    momentum = 0.9,\n",
    "    weighted_loss = False,\n",
    "    compute_mode = 'cuda:1',\n",
    "    train_batchsize = 512,\n",
    "    val_batchsize = 512,\n",
    "    num_epochs = 50,\n",
    "    num_workers = 8,\n",
    "    # metrics = ['hamming_loss', 'auroc', 'f1_score', 'aupr', 'accuracy', 'recall', 'precision'],\n",
    "    # metrics_average = ['macro', 'micro'],\n",
    "    metrics = ['hamming_loss', 'auroc'],\n",
    "    metrics_average = ['macro'],\n",
    "    patience = 10,\n",
    "\n",
    "    evaluate_train = True,\n",
    "    evaluate_val = True,\n",
    "\n",
    "    verbose = True,\n",
    "    results_verbose = False,\n",
    "    use_early_stopping = True,\n",
    "    use_tensorboard_logger = True,\n",
    "    wandb_project_name = 'DeepMTP_v2',\n",
    "    wandb_project_entity = 'diliadis',\n",
    "    metric_to_optimize_early_stopping = 'loss',\n",
    "    metric_to_optimize_best_epoch_selection = 'loss',\n",
    "\n",
    "    instance_branch_architecture = 'MLP',\n",
    "    use_instance_features = False,\n",
    "    instance_branch_nodes_reducing_factor = 2,\n",
    "    instance_branch_nodes_per_layer = [100, 100],\n",
    "    instance_branch_layers = None,\n",
    "    instance_branch_conv_architecture = 'resnet',\n",
    "    instance_branch_conv_architecture_version = 'resnet101',\n",
    "    instance_branch_conv_architecture_dense_layers = 1,\n",
    "    instance_branch_conv_architecture_last_layer_trained = 'last',\n",
    "\n",
    "    target_branch_architecture = 'MLP',\n",
    "    use_target_features = False,\n",
    "    target_branch_nodes_reducing_factor = 2,\n",
    "    target_branch_nodes_per_layer = [100, 100],\n",
    "    target_branch_layers = None,\n",
    "    target_branch_conv_architecture = 'resnet',\n",
    "    target_branch_conv_architecture_version = 'resnet101',\n",
    "    target_branch_conv_architecture_dense_layers = 1,\n",
    "    target_branch_conv_architecture_last_layer_trained = 'last',\n",
    "\n",
    "    embedding_size = 30,\n",
    "\n",
    "    comb_mlp_nodes_reducing_factor = 2,\n",
    "    comb_mlp_nodes_per_layer = [2048, 2048, 2048],\n",
    "    comb_mlp_branch_layers = None, \n",
    "\n",
    "    save_model = True,\n",
    "\n",
    "    eval_every_n_epochs = 10,\n",
    "\n",
    "    additional_info = {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT DIR: /data/dimitriosi_datasets/DeepMTP_v2\n",
      "Selected device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_path: b'/data/dimitriosi_datasets/DeepMTP_v2'\n",
      "current_path: b'/data/dimitriosi_datasets/DeepMTP_v2'\n",
      "current_path: b'/data/dimitriosi_datasets/DeepMTP_v2'\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdiliadis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220530_202822-u2y3c62v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/u2y3c62v\" target=\"_blank\">wobbly-snowflake-117</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Done\n",
      "Epoch:2... Done\n",
      "  Validating... Done\n",
      "Epoch:3... Done\n",
      "  Validating... Done\n",
      "Epoch:4... Done\n",
      "  Validating... Done\n",
      "Epoch:5... Done\n",
      "  Validating... Done\n",
      "Epoch:6... Done\n",
      "  Validating... Done\n",
      "Epoch:7... Done\n",
      "  Validating... Done\n",
      "Epoch:8... Done\n",
      "  Validating... Done\n",
      "Epoch:9... Done\n",
      "  Validating... Done\n",
      "Epoch:10... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 9\n",
      "Epoch:11... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 9\n",
      "Epoch:12... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 3 out of 10---------------------- best epoch currently 9\n",
      "Epoch:13... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 4 out of 10---------------------- best epoch currently 9\n",
      "Epoch:14... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 5 out of 10---------------------- best epoch currently 9\n",
      "Epoch:15... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 6 out of 10---------------------- best epoch currently 9\n",
      "Epoch:16... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 7 out of 10---------------------- best epoch currently 9\n",
      "Epoch:17... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 8 out of 10---------------------- best epoch currently 9\n",
      "Epoch:18... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 9 out of 10---------------------- best epoch currently 9\n",
      "Epoch:19... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 10 out of 10---------------------- best epoch currently 9\n",
      "Early stopping criterion met. Training stopped!!!\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_auroc_macro</td><td>▁█</td></tr><tr><td>val_hamming_loss_macro</td><td>█▁</td></tr><tr><td>val_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▂▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.62031</td></tr><tr><td>test_hamming_loss_macro</td><td>0.22727</td></tr><tr><td>train_auroc_macro</td><td>0.70609</td></tr><tr><td>train_hamming_loss_macro</td><td>0.2142</td></tr><tr><td>train_loss</td><td>0.39088</td></tr><tr><td>val_auroc_macro</td><td>0.63946</td></tr><tr><td>val_hamming_loss_macro</td><td>0.22717</td></tr><tr><td>val_loss</td><td>0.55555</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">wobbly-snowflake-117</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/u2y3c62v\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/u2y3c62v</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220530_202822-u2y3c62v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+-------------+\n",
      "|  mode | #epoch |  loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "| train |   0    | 0.6875 |       0.3028       |    0.4978   |\n",
      "| train |   1    | 0.5315 |         -          |      -      |\n",
      "| train |   2    | 0.4915 |         -          |      -      |\n",
      "| train |   3    | 0.4859 |         -          |      -      |\n",
      "| train |   4    | 0.4815 |         -          |      -      |\n",
      "| train |   5    | 0.4773 |         -          |      -      |\n",
      "| train |   6    | 0.4714 |         -          |      -      |\n",
      "| train |   7    | 0.4645 |         -          |      -      |\n",
      "| train |   8    | 0.4561 |         -          |      -      |\n",
      "| train |   9    | 0.4515 |         -          |      -      |\n",
      "| train |   10   | 0.4441 |       0.2142       |    0.7061   |\n",
      "| train |   11   | 0.439  |         -          |      -      |\n",
      "| train |   12   | 0.4318 |         -          |      -      |\n",
      "| train |   13   | 0.4275 |         -          |      -      |\n",
      "| train |   14   |  0.42  |         -          |      -      |\n",
      "| train |   15   | 0.4135 |         -          |      -      |\n",
      "| train |   16   | 0.4075 |         -          |      -      |\n",
      "| train |   17   | 0.4005 |         -          |      -      |\n",
      "| train |   18   | 0.3981 |         -          |      -      |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 0.6474 |       0.2644       |    0.5563   |      0/10      |\n",
      "| val  |   1    | 0.4988 |         -          |      -      |      0/10      |\n",
      "| val  |   2    | 0.4963 |         -          |      -      |      0/10      |\n",
      "| val  |   3    | 0.4943 |         -          |      -      |      0/10      |\n",
      "| val  |   4    | 0.4918 |         -          |      -      |      0/10      |\n",
      "| val  |   5    | 0.4909 |         -          |      -      |      0/10      |\n",
      "| val  |   6    | 0.4896 |         -          |      -      |      0/10      |\n",
      "| val  |   7    | 0.487  |         -          |      -      |      0/10      |\n",
      "| val  |   8    | 0.4842 |         -          |      -      |      0/10      |\n",
      "| val  |   9    | 0.4824 |         -          |      -      |      0/10      |\n",
      "| val  |   10   | 0.4838 |       0.2272       |    0.6395   |      1/10      |\n",
      "| val  |   11   | 0.487  |         -          |      -      |      2/10      |\n",
      "| val  |   12   | 0.4839 |         -          |      -      |      3/10      |\n",
      "| val  |   13   | 0.4974 |         -          |      -      |      4/10      |\n",
      "| val  |   14   | 0.4964 |         -          |      -      |      5/10      |\n",
      "| val  |   15   | 0.5091 |         -          |      -      |      6/10      |\n",
      "| val  |   16   | 0.5171 |         -          |      -      |      7/10      |\n",
      "| val  |   17   | 0.5367 |         -          |      -      |      8/10      |\n",
      "| val  |   18   | 0.5417 |         -          |      -      |      9/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   9    |  -   |       0.2273       |    0.6203   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "model = DeepMTP(config)\n",
    "# train, validate, test\n",
    "validation_results = model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating  performance... Done\n"
     ]
    }
   ],
   "source": [
    "# generate predictions from the trained model\n",
    "results, preds = model.predict(train, return_predictions=True ,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /data/dimitriosi_datasets/DeepMTP_v2/results/25_05_2022__10_27_12/model.pt...  \n",
      "Done\n",
      "Selected device: cuda:1\n",
      "Applying saved weights... Done\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/DeepMTP_v2/wandb/run-20220525_102836-14ekdw2r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/14ekdw2r\" target=\"_blank\">valiant-planet-62</a></strong> to <a href=\"https://wandb.ai/diliadis/DeepMTP_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "Epoch:1... Done\n",
      "  Validating... Done\n",
      "Epoch:2... Done\n",
      "  Validating... Done\n",
      "Epoch:3... Done\n",
      "  Validating... Done\n",
      "Epoch:4... Done\n",
      "  Validating... Done\n",
      "Epoch:5... Done\n",
      "  Validating... Done\n",
      "Epoch:6... Done\n",
      "  Validating... Done\n",
      "Epoch:7... Done\n",
      "  Validating... Done\n",
      "Epoch:8... Done\n",
      "  Validating... Done\n",
      "Epoch:9... Done\n",
      "  Validating... Done\n",
      "Epoch:10... Done\n",
      "  Validating... Calculating val performance... Done\n",
      "Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 9\n",
      "Epoch:11... Done\n",
      "  Validating... Done\n",
      "Epoch:12... Done\n",
      "  Validating... Done\n",
      "Epoch:13... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 12\n",
      "Epoch:14... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 2 out of 10---------------------- best epoch currently 12\n",
      "Epoch:15... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 3 out of 10---------------------- best epoch currently 12\n",
      "Epoch:16... Done\n",
      "  Validating... Done\n",
      "Epoch:17... Done\n",
      "  Validating... Done\n",
      "Epoch:18... Done\n",
      "  Validating... Done\n",
      "-----------------------------EarlyStopping counter: 1 out of 10---------------------- best epoch currently 17\n",
      "Epoch:19... Done\n",
      "  Validating... Done\n",
      "Starting testing... Calculating test performance... Done\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>▁</td></tr><tr><td>test_hamming_loss_macro</td><td>▁</td></tr><tr><td>train_auroc_macro</td><td>▁█</td></tr><tr><td>train_hamming_loss_macro</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_auroc_macro</td><td>▁█</td></tr><tr><td>val_hamming_loss_macro</td><td>▁▁</td></tr><tr><td>val_loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auroc_macro</td><td>0.58472</td></tr><tr><td>test_hamming_loss_macro</td><td>0.23111</td></tr><tr><td>train_auroc_macro</td><td>0.58376</td></tr><tr><td>train_hamming_loss_macro</td><td>0.23232</td></tr><tr><td>train_loss</td><td>0.4838</td></tr><tr><td>val_auroc_macro</td><td>0.58085</td></tr><tr><td>val_hamming_loss_macro</td><td>0.22975</td></tr><tr><td>val_loss</td><td>0.49449</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">valiant-planet-62</strong>: <a href=\"https://wandb.ai/diliadis/DeepMTP_v2/runs/14ekdw2r\" target=\"_blank\">https://wandb.ai/diliadis/DeepMTP_v2/runs/14ekdw2r</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220525_102836-14ekdw2r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+-------------+\n",
      "|  mode | #epoch |  loss  | hamming_loss_macro | auroc_macro |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "| train |   0    | 0.6341 |       0.2567       |    0.5211   |\n",
      "| train |   1    | 0.5626 |         -          |      -      |\n",
      "| train |   2    | 0.522  |         -          |      -      |\n",
      "| train |   3    | 0.5055 |         -          |      -      |\n",
      "| train |   4    | 0.498  |         -          |      -      |\n",
      "| train |   5    | 0.4943 |         -          |      -      |\n",
      "| train |   6    | 0.4923 |         -          |      -      |\n",
      "| train |   7    | 0.4906 |         -          |      -      |\n",
      "| train |   8    |  0.49  |         -          |      -      |\n",
      "| train |   9    | 0.4892 |         -          |      -      |\n",
      "| train |   10   | 0.488  |       0.2323       |    0.5838   |\n",
      "| train |   11   | 0.4884 |         -          |      -      |\n",
      "| train |   12   | 0.4873 |         -          |      -      |\n",
      "| train |   13   | 0.4862 |         -          |      -      |\n",
      "| train |   14   | 0.4856 |         -          |      -      |\n",
      "| train |   15   | 0.4858 |         -          |      -      |\n",
      "| train |   16   | 0.4848 |         -          |      -      |\n",
      "| train |   17   | 0.4846 |         -          |      -      |\n",
      "| train |   18   | 0.4838 |         -          |      -      |\n",
      "| train |   19   | 0.4838 |         -          |      -      |\n",
      "+-------+--------+--------+--------------------+-------------+\n",
      "====================\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| mode | #epoch |  loss  | hamming_loss_macro | auroc_macro | early_stopping |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "| val  |   0    | 0.5982 |       0.2297       |    0.5424   |      0/10      |\n",
      "| val  |   1    | 0.5323 |         -          |      -      |      0/10      |\n",
      "| val  |   2    | 0.5103 |         -          |      -      |      0/10      |\n",
      "| val  |   3    | 0.5018 |         -          |      -      |      0/10      |\n",
      "| val  |   4    | 0.4986 |         -          |      -      |      0/10      |\n",
      "| val  |   5    | 0.4972 |         -          |      -      |      0/10      |\n",
      "| val  |   6    | 0.4965 |         -          |      -      |      0/10      |\n",
      "| val  |   7    | 0.4961 |         -          |      -      |      0/10      |\n",
      "| val  |   8    | 0.4961 |         -          |      -      |      0/10      |\n",
      "| val  |   9    | 0.4957 |         -          |      -      |      0/10      |\n",
      "| val  |   10   | 0.4957 |       0.2297       |    0.5809   |      1/10      |\n",
      "| val  |   11   | 0.4953 |         -          |      -      |      0/10      |\n",
      "| val  |   12   | 0.4951 |         -          |      -      |      0/10      |\n",
      "| val  |   13   | 0.4952 |         -          |      -      |      1/10      |\n",
      "| val  |   14   | 0.4953 |         -          |      -      |      2/10      |\n",
      "| val  |   15   | 0.4952 |         -          |      -      |      3/10      |\n",
      "| val  |   16   | 0.495  |         -          |      -      |      0/10      |\n",
      "| val  |   17   | 0.495  |         -          |      -      |      0/10      |\n",
      "| val  |   18   | 0.4951 |         -          |      -      |      1/10      |\n",
      "| val  |   19   | 0.4945 |         -          |      -      |      0/10      |\n",
      "+------+--------+--------+--------------------+-------------+----------------+\n",
      "====================\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| mode | #epoch | loss | hamming_loss_macro | auroc_macro |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "| test |   19   |  -   |       0.2311       |    0.5847   |\n",
      "+------+--------+------+--------------------+-------------+\n",
      "Saving the best model... Done\n"
     ]
    }
   ],
   "source": [
    "# this is a minimal configuration needed for HPO methods like Hyperband\n",
    "config = {\n",
    "    'verbose': True,\n",
    "    'num_epochs': 20,\n",
    "    'num_workers': 8,\n",
    "    # 'wandb_project_name': None,\n",
    "    # 'wandb_project_entity': None,\n",
    "    # 'use_tensorboard_logger': False\n",
    "}\n",
    "# initialize the model and load the pretrained weights etc.\n",
    "new_model = DeepMTP(config, '/data/dimitriosi_datasets/DeepMTP_v2/results/25_05_2022__10_27_12/model.pt')\n",
    "\n",
    "new_model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "826a5bd2ad8dc46219a5d98b9d98bed8400ced7f93fb02df4538e6184f6a8e4f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
